2023.x.xx  -------------------------------------------------------->
xxxxxxxxxxxxxxxxxxxx  --------------------------------------------->  

TODO
1. 师兄的小论发表
2. 英语六级考试
3. 网络训练
4. 比赛
5. 贾鹏老师的火箭跟踪


2023.5.25
1. ln(0.5) = 0.69, 当前损失0.67, 目前看, 负样本和正样本数量差距过大, 正样本数量占总量0.05, 负样本数量占0.95, 网络对负样本过拟合了, 输出全部为0, 导致损失在0.67附近徘徊.
   重新设计损失函数匹配, 正样本权重提高为0.95, 负样本权重降为0.05(原本是0.5 / 0.5)
2. 重新训练 shift = 64 的模型
3. 看新的backbone的论文, 能不能尝试着把它的损失函数运算策略拿来用.


2023.5.24
backbone: MobileONE, 仅回归 cls 分支:  (主要测试 MobileOne 这个架构是否有收敛能力)
	1. shift = 0, cls loss在第5个epoch为: 0.43
	2. shift = 64, cls loss在第5个epoch为: 0.67
	如果不能收敛, 找一找为什么不能收敛. 
	
	
	
	
	

2023.5.24
1. 似乎找到了效果不好的根源, 可能是因为 shift 太小了,导致网络加入padding后找到了基本的规律, 就像是掉到了siamrpn的坑里...
2. 那么下一步要做的事情是: 将shift调整成64, 同时保证网络收敛, 首先要让分类分支收敛, 这个要依赖RepVGG, 先仿照SiamDW的backbone写成RepVGG的形式, 然后不进行回归分支的损失计算, 看分类分支是不是可以收敛.
3. 很久之前做过RepVGG的实验, 当时没有收敛, 找一下缘由
4. 分类分支收敛后, 重新对分类损失和回归损失进行训练, 回归损失的计算方式是: iou = e^(-loss), loss 降到 0.2 的时候, Iou几乎已经在80%了, 相当高的分数
5. 新冠复阳了, 回宿舍修养两三天.
6. 训练一个SiamFC的更简单的版本, 只回归目标的大小, 这样用到的参数量会更少, 如果做得好, 可以在发一篇论文, 加入硬件的话, sci4区应该没问题.
7. 还有一些训练好的数据, 还没有进行实验, 列在下方
	1. 纯siamfc, 无尺度变化, 记录fps.
	2. siamfc + 尺度变化, 但是只改变大小, 如 *1.03或者 *0.975
	3. 解释为什么目前的anchor free 无尺度变化反而成功率大幅上升 (padding)
	4. 测试当前正在运行的网络(search 抽取特征后,在某个阶段和互相关的图相乘,直觉上感觉不行,因为 padding)
	5. 去掉padding, 再次训练, 看网络是否可以收敛, 并记录效果如何
	6. 不去掉padding, shift增加到64, 弄一个可以收敛的网络
	7. 完全换成ocean的架构, 先互相关,shift = 64, 用互相关的图来进行尺度回归
	


2023.5.23
1. 看一下延长backbone之后的性能如何, 目前看起来不是很行...					(完成)
2. 训练相乘版本										(完成)
3. 看一下 shift=16, 分类是否可以收敛								(完成)
4. 写专利											(写了一部分了,换到ubuntu系统后又放下了)

2023.5.22
1. 延长回归的backbone，增加参数量和计算量，观察是否可以收敛					(收敛了, 但是性能极低)
2. 发现一个很有意思的事情：在当前架构下（分类的特征图和回归的特征图会有一个相乘的操作），只使用回归的损失作反响传播，那么分类的损失也会下降，而且降的不算慢，也许这代表着特征图中确实存在着一些尺度信息，分类的分支也会使用尺度信息作回归。					


2023.5.21
1. 研究fcos，发现参数量很大，看了运行机制，看是否可以稍作删减，运行在siamfc上，性能都是用参数堆起来的。



2023.5.20
1. 很具有嘲讽性的结果:增加3个3*3卷积后，成功率是0.307，准确率是0.405，如果将回归分支去掉，全部用初始的大小，成功率会增加到0.398，准确率会增加到0.531. 目前网络速度相当快，已经在500FPS上下波动了，当网络跟踪失败，fps会显著下降，这个应该操心一下，说不定可以用来作为SVM的代替版。	(resize有问题, 在某种情况下,它会耗费比卷积更多的时间,换到GPU上,或者向其他办法,可以显著增加网络速度)
2. 如果不加这三个3*3卷积，0.162 / 0.232，似乎增加卷积还是比较有用的...  没有最差，只有更差呀... (数据丢失了)
3. 下一步的计划：
	目前看有三个选择：
		1. 学习ocean，将两个特征图互相关之后进行卷积，看结果						(可以试试)
		2. 借鉴FCOS，将网络加深，做成一个分支暹罗，一个分支检测，害怕这个需要很深的网络		(暂时搁置, 参数量过大, 可以学习一点点)
		3. 继续在现有的网络上进行加深，同时不对分类分支进行回归，观察网络是否收敛，收敛的值应该在0.1 - 0.2 之间，验证收敛之dancer2后，再次进行整个网络回归，并测试。(完成, 实验失败)
		4. 记得看一下是不是分类分支过拟合了。								(未完成)
	三个东西同时搞
4. 快考六级了，以后晚上的时间用来学六级。									(为完成)
5. 将师弟添加到github群组中。											(完成)
6. 将tello的项目添加到github中。										(完成)
7. 目前网络的长时跟踪，相当差，恐怕是最差的。									(效果本就相当差)




2023.5.19
1. 参加校运会													(完成)
2. 训练并测试新的网络架构，实际上就是在回归分支上增加几个3*3卷积						(完成, 忘记了更改shift)




2023.5.18()
1. 重新写个backbone，在跑一下看看是否会收敛，或者直接用 alexnet.						(完成)
2. 重新看看基础知识，了解清楚为什么一个网络进行两次前向传播，结果会不一样，先测这个。				(还是没有弄清楚, 似乎这个现象只发生在RepVGG上)
3. 微笑活动，10:00 - 14:30，需要在外面跑。									(完成)





2023.5.17
1. 调服务器的代码，在服务器上准备数据集									(完成)
2. 单独测试分类损失，观察损失是否会降低，发现不会，并且分类+回归依旧不能收敛					

2023.5.16
1. 看一下data loader的代码											(完成)
2. 修改data loader的代码，变成完全的siamfc的代码								(完成)
3. 重新训练试试												(实验失败)


2023.5.15
1. 发现分类损失不降低，按理说应该是0.2上下，现在是0.5，在看一下训练的过程，是否有遗漏的东西。			(完成, shift太大了,网络收敛不了)
2. 现在的成功率是0.32，准确率是0.43，比人家差一半，这不行。							


2023.5.11 - 2023.5.14
1. 调训练用的代码，部署的时候 net.eval()									
2. 改写网络架构												(完成)
3. 等训练结果													(实验失败)


2023.5.10
1. 等待程序运行结果，也可先测试前面的pth					
2. 小论用《仪器仪表学报》审稿意见改造										(无法改造, )
3. 研究一下比赛的赛题选哪个？											(目前看, 效果还比较差, 无法参加)
4. 沟通数据集背景的使用											(完成)
5. yolo v5的使用/ mmdetection											(完成, 改用yolo v8)
6. 看一下程序还有哪些问题											




2023.5.9 
1. Ocean改造									√
2. 组会									老师太忙，没开
3. 小论改造，实验数据分析							(小论暂时搁置了)






2023.5.8
1. 把控制程序调好，准备记录路径						√
2. 数据集准备好								√
3. Ocean改造									太懒了




2023.5.7
1. SiamBan的修改版，写程序-跑程序-看效果，主要看昨晚想出来的架构行不行，为什么不行
2. 深入到互相关出来的数据看一下
3. cpu性能调整									√
4. 程序性能分析								√





2023.5.6
1. 看一下改进cross correlation 						√
2. 每隔epoch的pth都跑一下，写程序，这个不难					√
3. siamBAN这个是最主要的任务，看着太简单，了解一下细节				√
4. android上测试现在的backbone的时间						没时间
5. PID算法看看怎么调比较合适							交给师弟
6. 更改backbone的通道数看看效果降不降						没时间
7. 分析一下现在的速度瓶颈在哪儿						√
	实际上卷积操作只占用了25%的时间，剩下的时间主要集中在numpy.argmax、resize等操作上，这个看能不能想办法改进
8. 将互相关层放到上一阶段							√
9. 特征融合									√
10. 确定什么时候神经网络已经收敛了						√







end



2023.5.5
1. 查看训练进度
2. 看一下新的backbone的参数量和运算量，能在android上跑一下就更好了		√
3. 新的架构的实现，可更改的点：每层的通道数，网络的padding结构，尽快跑出结果	√ 通道数已经降低到128，再降就只能是96了，可以试试
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，cross corrolation也要升级					√ 还没有验证效果, 明天下午结果能出来个大概
5. SiamBAN的引入，anchor-free							读不懂绝对不能使用
6. vim的配置									√
总结：还没有在android上跑过，PID算法先看了一下，下个阶段是验证两种互相关的卷积方式哪一个更好一些，之后加上多个阶段的融合
      记得保存每个阶段的pth文件
;




2023.5.2 - 2023.5.4
1. 训练改进后的backbone							√
2. 来学校									√
总结：实际上是在SiamDW的基础上进行改进了，去除了1*1的通道层，增加了并行分支，identity有了新解法




2023.5.1
1. 看新疆大学的论文，并写文档汇报						√
2. 训练方法、从mobileONE迁移过来实现						√
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，corss corrolation也要升级					√
5. SiamBAN的引入，anchor-free							√
6. vim的配置
具体要做的实验：
1. 在siamfc上改backbone，用冲参数化之后的backbone作训练，先验证效果		
2. 在siamfc上实验特征融合，先不使用空洞卷集
3. 在siamfc上backbone有效果的话，用重参数化之前的backbone作训练
4. 在siamfc上实验空洞卷积特征融合
5. 在siamfc上实验ban
6. 感受野和训练数据的裁减方式做实验，看原siamfc的论文的讨论
总结：
1. 不能直接使用参数化过后的算法结构作训练，因为bn也被融合了，导致算法输出全部是0，加上bn不能保证算法相似性，只能先用大参数量跑了
2. torch.compile有问题，目前还用不了，感觉把算法全部迁移到ubuntu环境白耗心血。
3. 中期答辩的讲法：先将siamrpn++的结构，之后对三个模块进行升级，之后将部署的进展，应用的进展，最后讲接下来要做的事情
	有：	目标丢失机制的建立以及为什么能够建立
		跟踪算法的升级，PID算法
		接下来的部署平台 FPGA

		



2023.4.29
1. 新的架构设计



2023.4.28  -------------------------------------------------------->
1. 在Ubuntu上跑通nano。					√
2. 看SiamBan的论文，重新设计架构。				×
回家、跑通了nano，重新裁减了数据集  ------------------------------->  






2023.4.27  -------------------------------------------------------->
1. 项目存档，保留各个师兄师姐的代码，方便后续学习。		√
2. 在Ubuntu上跑通nano。					×
3. 看SiamBan的论文，重新设计架构。				×
4. pysot-toolkit的使用。					√
跑通了siamfc，手动降频了CPU，变得十分卡顿，不知道有没有问题，nano数据集准备需要时间，SiamBan简单一些。




2023.4.23 - 2023.4.26  -------------------------------------------->
1. Ubuntu系统安装
2. 数据集迁移


2023.4.22  -------------------------------------------------------->
1. 看一下搜参的改进有多少：似乎很少，只是提升了1个点不到，等模型稳定后在进行搜参吧，目前看应该是模型数据量太小
2. 测试新写的搜参程序：×
3. 新的backbone，现在是alexnet的改进版，下次参考HRnet来写一个新的backbone  	×
4. 写融合特征的程序										×
5. 开始新的训练										×
在OTB2015上跑了之前的程序，相当差，成功率只有0.4，不知道问题出在哪里。 ->




2023.4.21---------------------------------------------------------->
1. 安装cuda11.8 安装pytorch2.0，准备好切换的程序  	×(需要Ubuntu系统)
2.  搭建搜参的环境						未完成
3.  搜参完成后，重新看一下性能				√
4.  新的backbone搭建					×
5.  互相关的改进						×
6.  程序再次训练与调参					×
搜参用了太多时间和资源  ---------------------------------------------->  







2023.4.20
1. 先把训练结果跑出来看一下 	√
2. 看一下REP的最新论文		√
3. 搜参很重要，看一下SiamDW的搜参和nano的搜参 √
4. 跑出结果，改backbone，开始写专利
5. 互相关的操作要算一下
6. 记账				√
7. 打印跑步表格			√
8. SVM的常用包看一下资料，准备SVM的数据


2023.4.13

center map √
keep point √
focus√


2023.4.12
1. 研究一下为什么SiamRPN那么快，它的骨干网络是什么，网络参数量和运算量分别是多少。
2. 研究一下anchor free的tracker，先移过来。
3. RepVGG，把 MobileONE 的训练技巧复现一下。
4. 迅速将anchor free部署到Android，在原有的架构上改进。
   先做第二点，看一下ocean.
结果：
1. 跑通了trackit的测试代码，得到了Ocean的结构
2. 试着用anchor的尺寸作为卷积的尺寸进行特征提取
3. 






框架的要求
1. 支持测试的数据集：OTB、got10k、VOT数据集测试程序的编写，要有FPS。
    支持训练的数据集：VID、COCO、got10k，测试和训练分开。
2. 神经网络参数量测量程序的编写。
3. 各数据集的读取，以及dataloader的编写。
4. 激活函数换成ReLU6。
5. backbone、RPN、在这中间，应该使用注意力机制来搞，要思考如何将这些提取到的特征更高效的运用起来。
6. 硬件移植，先搞edgeboard和K510，来年Jetson orin nano发布之后，如果能买到，使用orin nano进行部署。
7. lighttracking、FEAR-L、FEAR-XS、FEAR-M、Ocean（Offline）、STARK（S-50）、SiamFC++（AlexNet）、SiamFC++（GoogleNet）、
	SiamRPN++（mobileNet-v2）、SiamRPN++（ResNet-50）的实现，并且整合到框架中，而不是多个项目工程同时跑数据、LightTrack、STARK（Lighting）
8. Efficient-net、mobile-net v2、RepVGG的训练方式、MobileOne的组织结构，都要学一下。
9. 要有logging，要有断点续训，不需要分布式，针对不同的算法要生成不同的文件夹来存放数据，不然每次要改就很烦。
10. 测试工具：vot toolkit   pysot toolkit  vot toolkit


要尽量使用别人写好的代码，而不要试图自己去写完所有的代码，最好找已经存在的库来做。


1. 尽量少的分支
2. 尽量少的分组
3. 尽量使用3*3卷积
4. 输入通道和输出通道尽可能一致
5. 尽量少的element操作

6. 
 目标是尽量少的参数量 + 尽量少的MAC





SiamDW
1. 步长 4 / 8
2. 最终感受野 80%
3. 无padding


输入 127*127 的图片
1. 一个 3*3 无padding的影响
	一个点是3
2. 两个 3*3 
	一个点是

3*3		3
3*3		
3*3
3*3
3*3
3*3
3*3		
3*3		3
