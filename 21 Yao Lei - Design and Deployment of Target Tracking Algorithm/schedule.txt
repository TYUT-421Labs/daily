2023.x.xx  -------------------------------------------------------->
xxxxxxxxxxxxxxxxxxxx  --------------------------------------------->  

TODO:
1. Nanotrack的训练
2. 专利
3. 工作


2023.9.19
1. 赶紧写专利（重点）
2. 改好的head应该开始训练了
3. 使用无padding的网络结构开始写anchor-free的跟踪器，写好开始训练吧

2023.9.18
1. 重新使用预训练模型训练了用mobileone做主干网络的nanotrack，最终收敛到0.19，分类损失降到0.029，回归损失降到了0.161
	[2023-09-18 09:54:46,071-rk0-train.py#261] Epoch: [50][0/18750] lr: 0.000500
		batch_time: 0.363587 (0.392005)	data_time: 0.000159 (0.000330)
		cls_loss: 0.008570 (0.029082)	loc_loss: 0.190246 (0.161141)
			total_loss: 0.198816 (0.190224)	
	[2023-09-18 09:54:46,072-rk0-log_helper.py#102] Progress: 937500 / 937500 [100%], Speed: 0.392 s/iter, ETA 0:00:00 (D:H:M)
	比之前不使用预训练模型，损失多下降了0.03

2023.9.14
1. 注意到一个事情，之前训练的时候，负向样本概率值是0.0，现在调整为0.2.可能导致网络收敛的有些奇怪，先做一个对照试验。


2023.9.12
1. 不能把目标定的太高，先满足专利要求，稍微好一点可以试着发中文核心，主要是自己比较笨，慢慢来吧。
2. 目前还是希望能把网路做的小一点，首先是backbone，预训练虽然调通了，但是没有训练的时间，先直接用别人训练好的pth吧，希望能快速出成绩。
3. 将后续的分类层和回归层也做成RepVGG类型的。
4. 在整个网络训练好之后，想办法进行剪枝，让网络更快一些。
5. 性能够好，创新点主要体现在网络结构上了吧。


2023.9.7
1. 没有用预训练网络训练的跟踪器训练好了，最终收敛到0.23，虽然也能用，但是距离之前的0.15还是有很大距离的。
2. 先写好对新的backbone做预训练的框架，以后要对新的backbone做预训练。
	a. 学会更改backbone的结构			√
	b. 学会学着用不同的batch size，并且让学习率随着batch size做更新。 √
3. 在跟踪器训练过程中，在前10个epoch，不对backbone做参数更新，这个要重写一下。
4. 目前最重要的还是专利，先把专利写出来，有点安全感，简历还是得接着投。
5. 让两个师弟开始学着用Git，每天写日志进行更新。

2023.9.6
1. 不使用预训练网络，网络收敛在0.23，使用预训练网络，收敛到0.15，也就是说，不使用预训练网络，需要更长的训练时间。
2. mmpretrain调通了，之后可以用它来进行网络预训练。

2023.9.4
1. 重新训练以MobileONE为backbone的nanotrack，看一下训练过程，实在弄不清楚改进版哪里弄错了，为什么收敛不了，目前看，loss在0.25以上，基本上就代表着模型不能用，loss在0.33，不管怎么搜参，VOT2018的EAO都是0.1左右，repvgg也一样，loss 0.28。
2. 目前猜测有可能backbone需要先用分类网络训练一段时间，可能是参数初始化有问题。
3. 整个训练网络的过程应该是这样的：
	先用backbone去识别imageNet，得到初始化权重。
	使用有权重的backbone去训练nanotrack，loss一般在第30个epoch收敛，如果在0.25以上基本上这个backbone就有问题，可以放弃训练了。
	50个pth中，全部在VOT2018上跑一遍，找到后期较优的pth。
	使用搜参算法对较优的pth进行搜参，一般能够将eao增加0.1左右，这个看运气。
	最重要的是整个网络训练的时候一定要收敛，如果不收敛，其它的都不是很行。
4. 另一个问题是 为什么对mobileone稍加改动，整个网络就立即无法收敛了，
	目前的猜测是：
		1. 感受野不够，网络减小了一层3*3卷积，导致感受野变低了
		2. 网络参数量不够，最后一层卷积占用的参数相当多，那个1*1卷积不一样去掉，参数量导致网络客观上无法收敛。
		3. 改进后的mobileone没有使用ImageNet训练过的预训练权重（等到没有使用预训练权重的MobileOne训练出来之后看看吧）
	先整几个实验把这些原因都搞一搞。
5. 学一下shuffleNet，在stride=2的时候，将原图使用3*3 average pooling stride=2，将尺寸变成一样的，然后concat，更多的保存原图信息。
tips：
	在使用一个新的backbone的时候，先使用imageNet对这个backbone做预训练，这个步骤很重要吗？
	答：对于新的backbone，进行ImageNet预训练是非常有益的，尤其是当你的任务数据量不大或者计算资源有限时。预训练能够帮助模型快速收敛，也能够达到更好的性能。这里有几个原因：

		避免过拟合：预训练模型在大量数据上训练过，因此它能够学习到更泛化的特征，这可能有助于避免过拟合。

		加速收敛：使用预训练模型可以作为一个良好的初始化，有助于模型学习过程中的收敛速度。
	
		提高性能：有研究表明，在许多任务中，使用预训练模型作为初始模型都能够取得更好的性能。
		但是，如果你的任务数据量很大，而且与ImageNet数据差异很大，或者你有足够的计算资源，那么直接在你的任务上从零开始训练也是可行的。





	
2023.9.3
1. 实验日志没保存好，之前有些模型需要重新跑，使用mobileone，计划表里记录的nanotrack可以收敛到0.15就很离谱，目前最好的模型也只收敛到0.27，但是真实数据找不到了，只能重新跑这个模型，还好模型文件还存着，很奇怪的样子。
2. 直接将模型参数文件导入到模型中，看了一下loss，真的收敛到了0.20， 怎么会这么低呢，确实比nanotrack低很多，今天的任务就是找一下这个模型到底做对了什么...
	cls_loss: 0.013140 (0.036129)	loc_loss: 0.149222 (0.170411)
	total_loss: 0.162361 (0.206541)	
3. 模型训练是个玄学



2023.8.26
1. 看了一下以往的经验，之后monbileNet收敛的很快，MobileONE因为其特殊的特性，似乎需要更多的训练量，大概要300 epoch，将几个训练集都用上，loss可以降到0.33，但是nanotrack:
	[2023-07-23 01:10:25,370-rk0-train.py#239] Epoch: [50][3115/3125] lr: 0.000500
	batch_time: 0.071016 (0.101681)	data_time: 0.000000 (0.016204)
	cls_loss: 0.021495 (0.041657)	loc_loss: 0.215735 (0.211768)
	total_loss: 0.237230 (0.253425)	
	[2023-07-23 01:10:25,370-rk0-log_helper.py#102] Progress: 156240 / 156250 [99%], Speed: 0.102 s/iter, ETA 0:00:00 (D:H:M)
2. 头疼...，训练的成本太高了，时间不够用了，只能先把参数拉满，然后直接大规模训练了。。。  好费钱 0.0





2023.8.23
1. 不知道为什么网络收敛不了了， kernel size=5比kernel size=3更加无法收敛，kernel size=5， loss在0.55， kernel size=3， loss=0.5(应该是训练时间太短，网络还没有完全收敛)
	kernel size = 3 + SEblock， loss = 0.5，也就是SEblock似乎没有发挥什么作用， 很是不懂，这肯定不能正常工作。


2023.8.19
1. 好坑爹啊，不知道是温度相关还是有其他因素影响，今天重新测试backbone的运行速度，mobileONE的速度降到了10ms，之前一直在22ms徘徊，不是很懂这个机制...，
	刚又看了以下，最后一个block的stride=2，虽然只是一个卷积块，但是依旧会对网络的速度造成比较大的影响，必要的时候可以直接去掉最后一个block。（去掉最后一个block之后，网络参数量不足以支持模型收敛了，不能去掉，想别的办法）
2. 按照之前的测试来看，5*5可分离卷积的速度是最快的，今天将backbone的block都换成了5*5卷积，测试发现速度下降比较小，再试一下SEblock（还是没弄明白为什么5*5的卷积比3*3的卷积更差，这得再想一想）



2023.8.18
1. 按照之前的思路，想办法将MobileONEblock换成5*5卷积，将通道数加上去，看一下网络是不是能够收敛，之前的Android测试中，5*5卷积的速度比3*3卷积的速度更高一些。
2. 关于之前换互相关操作的想法，之前的互相关7*7在25*25的方向上卷，这7*7中，目标本身占了4， 周围的环境占了3， 那是stride=8的时候，当stride=16的时候，感受野已经远远超过了255，卷出来的每个像素都包含原有图片所有的信息，直接使用7*7上的所有点在25*25上所有的点进行点积，求相似度，效果不会下降太多，light track、nano track都使用了这种互相关，效果还不错。当stride使用16的时候，最终255 -> 16, 127 -> 8, 这种情况下16卷8只剩下9*9，特征图有点小，16卷2也还行，可以随缘试试。



2023.8.17
1. 将LightTrack的head移过来，配合原生的MobileONE和改进成3*3的MobileOne配合使用进行训练，似乎提升较小。
2. 不太明白为什么效果会这么差，MobileONE的潜力应该和MobileNetV3的潜力差不多，但是总是效果不好。
3. 在改一改MobileONE吧，将卷积的尺寸对齐LightTrack...
4. RepVGG可以提升一些性能，但是不会很多，在训练Rep类型的网络的时候，将branch设置为1，效果好的话在使用branch=2进行训练。
5. SEblock全部加上。
6. 使用Rep类型的网络的话，由于网络的层数太多，如果使用1*1卷积随意的改变网络的输出特征图的通道，残差结构就不能使用，这样会很快的丢失原图信息，所以MobileONE使用了只有4个stage的网络，所以之前将MobileNetV3改写成MobileONE的努力失败了，因为1*1随意的修改通道，导致残差结构不存在，特征丢失，结果就是无法收敛。从这一点来看，要保证网络感受野和LightTrack或者MobileNetV3相似，但是网络的stage依旧要有4或者3个，就不能随意对的单个MobileOneBlock进行设计了。基于这个思路，之前31层的MobileONE使用的方法是扩展每一层3*3卷积数，将感受野叠上去，但是网络的stage不变，依旧是4个，有效果，但是效果不是很好，因为网络的深度增加了，网络的通道数相应的减少了，网络收敛的不好，31层的网络没有原来MobileONE20层的网络效果好，之后的思路恐怕得往5*5卷积上打主意了... 但是网络的 stage 依旧不能有很大变化，之前使用 MobileOneBlock设计网络浪费了很大时间，不能在踩坑了。




2023.8.12 - 2023.8.16 休息


2023.8.11
1. 看一下点卷积，什么原理，如果没有互相关的特性， 可以将x和z的backbone分开。
2. 看一下lighttrack的感受野，将mobileone写成一样的。
	看了lighttrack的网络结构，不能比MobileOne快，它的网络结构比mobileone还长，甚至还有se block，在Android上的速度是：22ms， 看起来stride=16， 7*7卷积比较多，降低了计算量。
	重新使用mobileONE重写以下lighttrack的结构吧，只有15个block，比之前的22个block少，但是感受野比较大，因为7*7卷积比较多，先试一下。
	不太看好。
	将所有的lighttrack结构换成 3*3之后，似乎relu太多了，对元素点的操作导致速度变得好低，已经降到30ms。
	只能是直接把7*7写上去了... 或者换空洞卷积 0.0
3. 看一下light track的head，移过去。
4. ocean中间的那个东西很好用，可以拿过来试试。
5. 看一下改完的模型的速度如何。




2023.8.9-2023.8.10
1. 又重新魔改mobileONE,重新训练nanotrack，取得了还不错的结果。
2. 准备使用空洞卷积。
3. 使用light track的head对nanotrack进行魔改。
4. 今天一定要把nanotrack的互相关改回来。
5. 看light track的论文，该拿的拿。
6. 将卷积换成 7 * 7或者 5 * 5， 应该还是用7 * 7比较好吧。
7. light track中有一些训练技巧，先取过来看看。

2023.8.7 - 2023.8.8
1. 重写backbone，时殷弘mobileNet V3的结构，失败了

2023.8.5 - 2023.8.6
1. 准备大疆的笔试



2023.8.4
1. 找新的backbone的bug
	1. stride=2不可以在卷积 1*1上使用，会丢失太多信息。
	2. seblock的激活函数是 h-sigmoid
2. 重新使用新的backbone再次训练。

2023.8.3
1. 参加大疆的测评
2. 写新的backbone，具体地说，将mobileNet v3的激活函数拿了过来，将seblock加上，将mobilenet v3的结构换成mobileone的结构，重新训练。

2023.8.4
1. 

2023.8.1-2023.8.2
1. 写好了测试骨干网络在Android上延迟的框架，并进行了测试，结果如下；
	RepVIT，声称在iPhone12上1ms以内，并给出了结果图，实际上在Android上运行，结果相当差，CPU 65fps，GPU 100fps左右。
	MobileONE，声称在iPhone12上1ms以内，实际上在Android上运行，GPU大概20ms，加上其他前后处理，一共耗时33ms。
	MobileNet V3，在Android上能到16-18ms，连带了最后的全连接层，实际上可以小一点。
	nanotrack 的 mobilenet v3 light，在Android上的延迟的12ms，它比mobile net v3更小一些。
2. 综上所述，实际上在Android上使用骨干网络，还是用mobileNet v3更好一些，之前的研究有偏差。
3. 所以，今天的工作如下：
	1. 将MobileONE中的block拿过来，那个是 3*3 + 3*3 + 3*3 + 3*3 + 1*1 + identity，最后融合成一个卷积块，已经够用了
	2. 将mobilenet v3的结构取出来，断开其中的跨链接层，变成plain结构，使用mobileone做为blovk， se block可以测试在哪里加上比较合适。
	3.



2023.7.31
1. 帮同学看一下lenet-5在Android的运行速度（满载）
2. 改进nanotrack，重新开始训练，试图增加网络的性能。
3. 改简历，投给大疆。
4. 看直播，FPGA部署神经网络。
5. 看一下mobilevit的论文，虽然不打算使用这个backbone，但是要用一些它的技巧，去优化现有的框架。

2023.7.30
1. 重新测试了MobileONE的运行速度，在Android开着高性能模式的时候，跟踪速度可以到20FPS，推理速度在 12ms - 31ms 波动， 目前没有用到手机上的GPU，只使用CPU来跑，只是，iPhone12 Pro使用的CPU是A14，它的性能比天玑8100要好很多，没想到能差出10倍以上。
2. 下一步，重写MobileOne的结构，使用更少的参数量和计算量。
3. 换用原来的互相关机制
4. 重新对nanotrack使用多数据集进行训练，将MobileOne用到的训练机制复现。 
5. 搜参程序运行的很好，目前Eao已经到了0.3243239734191375，比nanotrack v1要高一些了。
6. nanotrack在Android上的移植，将进程设置为8之后，网络速度有了比较大的提高，使用GPU和CPU都在25-30FPS，我认为还有提升的空间，另外，MobileOne的执行时间在15-25ms，太高了，按理说应该是1ms以下的，手机发烫会导致网络的速度下降，应该注意。



2023.7.29
1. 继续昨天的任务，先写搜参 √
2. 将以MobileONE为backbone的tracker部署到Android上，看FPS，肯定还要优化的，先看一下速度。
	在Andorid手机上的速度大概是15FPS... 好低，不知道为什么，可以考虑单独测一下backbone和head用的时间。
	测得速度是100ms+，这不是很正常，太慢了一些，MobileONE在Iphone14上的速度是1ms-.
3. 参数量和计算量，果然还是比较重要的，计算量尤其重要一些。


2023.7.28
1. nanotrack使用MobileONE收敛到0.18就不再向下收敛了， SiamRPN使用resnet22收敛到0.5就不再收敛了。
2. 需要更好的训练策略，最好把MobileONE的直接拿来用，一会儿去调一下。
	要写很多新东西，之前没见过的东西。开始使用git管理版本。
3. 直接使用nanotrack的Android代码，测一下mobileone在手机端的运行速度。
4. 写测试代码，看mobileone在dtb上的性能。		√
	test.pth VOT2018  lr-0.39  pk-_0.148  win-_0.462
	------------------------------------------------------------
	|Tracker Name| Accuracy | Robustness | Lost Number |  EAO  |
	------------------------------------------------------------
	|   TESTR0   |  0.565   |   0.445    |    95.0     | 0.265 |
	------------------------------------------------------------

	Nanotrack
	------------------------------------------------------------
	|Tracker Name| Accuracy | Robustness | Lost Number |  EAO  |
	------------------------------------------------------------
	| NanoTrack  |  0.542   |   0.328    |    70.0     | 0.311 |
	------------------------------------------------------------
	好怪异的结果，Accuracy和Robustness都比较高，EAO和 Lost Number居然比较低，先写一个搜参程序，试试咋样，0.265太低了。
5. 将resnet22去掉一层，重新使用got10k 600000训练，使用服务器，希望它可以接着收敛，实在不行，再看一下nanotrack的训练策略，将这个策略运用到resnet22上。
6. mobileOne是否可以接着降低参数，通道数和网络深度 看可不可以降。
7. 理论上，使用多个数据集同时训练，可以提升模型3.5%左右的auc，这一点适用于两个模型。
8. mobileone的互相关，是不是可以换成别的。
9. resnet22可不可以写成rep的形式，看一下是不是可以提升效率。


2023.7.27
1. 新的网络架构 骨干网络 -> rpnhead 训练好了，成功率0.50.
2. 下一步：
	1. 使用更好的训练集训练这个模型
	2. 使用更大的backbone训练模型，看这个模型的潜力是多少，目前用AlexNet，它似乎还没还有完全收敛。
	3. 发挥出模型的潜力之后，使用mobileOne去缩小backbone的参数量和计算量，取均衡。
3. 另一个问题，似乎显卡在经过一整年的训练之后，性能下降了很多，有可能是设置的问题，目前还没有办法解决它。 
4. 使用mobileone做backbone的nanotrack，已经训练好了，准备测试。


2023.7.23
1. 先把MobileOne的基本架构弄来，然后重新训练一下看看吧。

2023.7.22
1. 重写mobileone，快速训练ocean。
2. 更换siamrpn的backbone，开始训练。
3. 目的是快速出结果，之前的想法不能实现，现在就是要一个能正常运行的结果。

2023.7.21
1. 昨天和前天看了一下Ocean原生的网络模型的训练时候的情况，分类损失已经降到了0.06，回归损失降到了0.14，网络层数深带来的拟合性是浅层网络达不到的。
2. 暂时放弃之前的想法，先把siamRPN和nanotrack换一换backbone，重新训练一下看看效果。
3. Ocean 或许不应该训练backbone，只训练head说不定都会更好一点。
4. 今天的几个任务：
	1. nanotrack跑通
	2. siamrpn跑通
	3. 两个模型换backbone
	4. 重写VGG类型的mobileone，放到Ocean上进行训练。

2023.7.18
1. backbone换成 MobileOne， 进行训练
2. 找center ness的bug，收敛不了，不知道为什么。


2023.7.17
1. 测试，用新的数据集跑了50个epoch， 
	CLS_ORI Loss:0.17050
	REG Loss:0.11369
	Loss:0.28419
	结果：0.2，还是很差，为什么相同的架构，我的网络结果就这么差呢？
		还是老老实实的把ocean写出来，训练一下看看吧...
2. 使用点卷积，将特征图的尺寸提升到 21 * 21 之后， 
		|        OceanT21        |  0.346  |     0.000      |   0.501   |
		还是很差，相对于 17 * 17 的时候，成功率提升了5%
3. 使用stride = 4的backbone，特征图尺寸是33 * 33：
		
4. 对center ness分支分析，目前写的东西，无法收敛，有问题。
	看完了meta实现的fcos，并没有什么差别，我不能理解为什么无法收敛，最终center ness收敛值为0.5，我认为至少应该在0.2以下。

5. 使用mobileone写一个跟踪器， stride = 8， 加入裁剪的因素， 特征图的大小为 25 * 25. 重新训练。
	# [1 3 255 255] -> [1, 128, 32, 32]
	# [1 3 127 127] -> [1, 128, 16, 16]
	# crop [16 - 8] -> 8       32 - 8 + 1 = 25, 25*25
	# 加入center ness分支的siamfc可以预见的效果不太好，先把mobileone的前三层送到ocean尝试一下。


2023.6.30 - 2023.7.1
1. 尝试复现SiamDW
2. 学习 rt-thread


2023.6.29
1. 使用相同的训练方法，使用相同的网络架构，无法重现SiamDW的结果。
2. 可以直接使用原有的pth和架构，迅速搭建出anchor free的架构来进行跟踪。

2023.6.28
1. 有如下结论，
	不同的网络结构对应着不同的超参数，超参数的寻找很重要
	同一个网络结构的不同pth，使用的超参数应该是一样的，如ResNet22W，官方给出的最优解是0.6589，使用不同的Pth去做测试，得到的最好结果是0.647，相差0.011，也就是说，寻找超参数的过程如下：
	1). 先写好网络，进行训练，得到50个pth文件
	2). 将50个pth文件使用寻常的超参数进行测试，得到结果最好的那一个。
	3). 将结果最好的那一个，使用搜参算法寻找超参数，直到网络收敛。
	4). 使用寻找到的超参，对50个pth进行测试，找到最好的那一组结果。

	网络的预权重很重要，找到可以使用的网络预权重重新进行训练试试。

2. 现在有如下困惑：
	1). 为什么SiamDW给出的pth是33，但是它的损失还是0.14，看现在情况，第33个epoch早都已经过拟合了，损失应该在0.1以下。

3. 现在的任务
	1) 继续尝试复现SiamDW
	2) 使用MobileOne重新训练一个SiamBAN，试一下看看效果。

2023.6.27
1. 等待SiamDW训练完成

2023.6.26
1. 尝试复现SiamDW的训练过程

2023.6.25
1. 他们可能使用了很大的数据集，导致网络在第33个epoch损失值已经下降到了0.14.
2. 目前最关键的是找到他们挑选pth的方法。如果用到了很大的数据集 + 对每一个epoch产生的模型进行测试 + 搜参，那么需要很大的算力。
3. 尝试复现SiamDW，看一下标准的训练过程是怎么样的。


2023.6.24
1. 写了ray和gene的搜参算法，调试好了软件包。
2. 配置了pysot环境

2023.6.23
1. 运行siamdw原始程序，训练到了第38个epoch，发现损失到达0.17，不在下降
2. 重新使用siamdw给出的pth进行训练，发现他们选择了第33个epoch的pth，此时损失值在0.14。


2023.6.19 - 2023.6.22
1. 尝试恢复原来的系统，失败。
2. 重新安装Windows10系统。


2023.6.18
1. 电脑坏掉了，具体原因如下：
	为了写搜参算法，需要用到ray程序包
	ray包不能正常运行，怀疑是显卡驱动和cuda不匹配
	重装cuda，对齐驱动和cuda版本，对齐后发现屏幕亮度保持最亮，无法调节
	查资料发现是Ubuntu kernel与笔记本电脑不匹配
	重装Ubuntu kernel，但是由于kernel head无法编译，导致系统崩溃，无法安装新的程序
	备份Ubuntu资料后，使用rm -rf /* 来删除系统
	rm -rf /*直接将Windows引导也删掉了，两个系统都无法进入，只好全部重装
		

2023.6.15 - 2023.6.17
1. 参加六级考试

2023.6.11 - 2023.6.14
1.准备数据，参加中期答辩
	
2023.6.8 - 2023.6.10
1. 准备各个版本的程序, 跑出结果, 中期答辩用
2. 英语, 作题




2023.6.7
1. 准备中期报告, 不再向前探索, 先跑出中期要用的数据, 如下:
	1. 找一台服务器，跑ocean的原生训练过程，观察损失的变化，以及最后收敛到哪里，shift=64.
	2. 找siamdw，这应该是跑的最好的Siamfc，直接将最准确的大小信息输入进去，看成功率如何。
	3. 找服务器，在siamdw的基础上更改backbone，观察效果，先加rep训练
	4. 找服务器，在siamdw的基础上改backbone，观察效果，加上repvgg vainilla net，shift 一律4
	5. 再试一下label的更改，观察是否对输出有提升。
	6. 希望可以尽快出成果，这一次直接加载训练好的backbone，训练后面的几个卷积层，问题在于解决跟踪器的问题
2. 准备中期PPT
3. 跟老师汇报最近的进度
数据: siamfc使用新的架构之后, 使用bounding box的size, 最好的结果可以达到0.697的跟踪成功率, lighttrack的成功率是0.59, 
	

2023.6.6
1. 等待网络收敛, 观察效果													(效果大致只能到0.56, 不好, 换回原有的label重新训练)
2. CET6															(完成)
3. 从训练过程中来看, 加上hanning窗之后, 预测值最大的点与实际上最大的点总是相差5个单位的距离, 这需要在找一找原因, 尤其是不管网络是否收敛, 总能相差5个单位有点奇怪, 如果能把这个东西搞清楚, 那么说不定可以提出对应的解决策略.



2023.6.5
1. CET6															(完成)
2. 总结比赛															(完成)
3. 测试新的网络能力														(完成)
总结:    
    将特征图resize为255 * 255, 与真正的label进行损失函数计算, 网络的性能下降了, 在训练中, 网络的损失收敛到 0.28 不再向下收敛, 有两种解决方法:
	1. 使用新的backbone, 观察是否可以收敛的更好										(依旧收敛到0.27左右, 感觉新的backbone似乎也就那样...)
	2. 将特征图变小, 重新计算损失, label依旧是梯度下降									(在进行尝试)


2023.6.4
1. 距离损失无法进行反向传播, 重新设计损失函数, 将距离的损失加入到lebel中, 使得更有非线性的网络更能发挥自己的能力.		(完成)



2023.6.3
. 调两阶段训练的代码														(完成)
2. 坑: 在stage2中, 固定backbone参数的时候, 没有固定bn层的参数, 导致训练过程中网络的bn层一直在进化, 结果每个conv层输出的结果不一样, 找bug, 很久.	(完成)
3. 将跟踪分成两个部分, 分别是分类和回归, 分类主要预测物体的位置信息, 回归预测物体的大小信息, 这两个部分单独进行测试, 使用gt中的target size, 使用cross corralation得到分类图. (完成)
4. 假设有一个完美的跟踪器可以得到目标的尺度信息, 最后的成功率可以达到0.659, 准确率可以达到0.796, 这说明互相关机制还不能很好的结果目标位置的问题.
5. 由于将分类分支用于目标的位置回归, 所以考虑加入距离的损失, 也就是说, 对于分类分支有如下几个优化:
	1. 损失函数 + FCOS类似的距离损失.											(距离损失无法反向传播, 失败)
	2. 网络的架构, 从alexnet转换成siamdw的bacobone.									(完成)
	3. 网络块, 使用 RepVGG 和 香草网络相融合的形式, 探索更好的性能.							(完成)
6. 今天先写好FCOS类似的新的损失函数, 看怎么设计比较好一下. 具体的讲, 为了更贴合实际的预测过程, 不再使用17 * 17的特征图计算分类损失, 而是将17*17的特征图resize为(17*16) * (17*16)的特征图, 与276 * 276 的标签计算分类损失, 另外, 在272*272上找到最大值的点, 计算最大值的点相对于中心点的距离, 将这个距离作为损失的一部分加入进去, 看一下分类分支会不会有大的变化, 或者直接在生成一个272*272的图.															(效果变差, 失败, 未找到原因)




2023.6.2
1. 加入VanillaNet之后, 由于激活函数在训练过程中会发生变化, 再加上横向和纵向对网络的扩展, 网路训练一次需要两天, 效果出的太慢了.
2. 重写一套程序, 仅使用简单的siamfc作为主体框架, 先完成训练, 需要重写 dataloader  网络结构  前向传播等等.			(完成)
3. 將resize写道cuda里, 增加网络速度, 之后可以jetson nano测试, 有一个四区的杂志接收.	


2023.6.1
1. 重点训练集表现正常, 测试集特征层最外层数值很大的问题.
2. 去掉多层的激活函数, shift=32重新训练.
3. 重写 dataloader, 去掉随机的shift这个因子, 扩大网络搜索范围.
4. 在 shift = 64, 去掉多层激活函数的情况下, 训练15个epoch, 网络收敛不了
5. 去掉多层激活函数的情况下, shift = 32,网络似乎依旧无法收敛, 尝试在backbone中加入有限 3*3 padding = 1的卷积, 在进行尝试.
6. VanillaNet的激活函数看起来似乎仅仅是在每个relu后面跟了一个N * N的卷积, 增加了网络计算参数, 带来了非线性性能, 但是不适合无padding的跟踪.
7. 目前来看, 无padding的backbone似乎不可能实现, 是一个两难的现状:
	a. 全部使用无padding的网络, 这样限制shift < 16, 首先不能确定回归分支是否可以收敛, 无paadding, 分类分支只能使用三层.
	b. 使用有padding的网络, 不对shift进行限制, 直接拉长为64.
	c. 实际上, 分类分支需要padding的限制, 回归分支不受padding的限制, 可以分别训练, 第一阶段训练分类分支, shift = 16, 第二阶段固定backbone的参数,, shift = 64对回归分支进行训练, 可以再加一些卷积, 促进它的收敛, 实际上两个过程中不一样的东西是shift.
8. 先试一下两阶段训练, 第一个阶段shift = 16, 学一些如何两个阶段分别训练不同的参数
    
    TODO:  现在开始训练第一阶段, 位置不回归.
    	   stage 2: 先加载之前训练的部分, lr 不更改, 更改 param 的设置, 将connect的可训练参数写到优化器中, 重新进行训练






2023.5.31
1. 等待程序跑出结果, 并测试
2. 找EI会议, 改论文, 投稿
3. 写六级的卷子
4. 如有可能, 将resize的操作写到cuda里, 看是否可以增加网络速度.
实验记录: 从没见过这么差的性能, 而且还有很诡异的现象, shift = 32, 训练集跑出的特征图完全正常, 测试集上特征图的最外层的数值相当大, 查了一晚上, 没有什么发现, 预测如果将新的激活函数去掉会好一些, 但是这是为什么呢? 因为shift没有到达64吗? 其他人所有的卷积都加了padding, 也没有出什么问题, 为什么这个网络这么奇怪呢。我对于跟踪网络的理解还是比较浅。




2023.5.30
1. 身体不适, 等待电脑跑出结果.



2023.5.29
1. 参加师兄答辩
2. 经验如下:
	1. 专家看文件的顺序: 盲审结果 -> 自己写的评语 -> 成果 -> 摘要 -> 目录 -> 随便翻一翻.
	2. 专家在说话的时候, 不要抢话, 很容易让人家故意要问倒你.
	3. 专家知道整个毕业论文的目录在什么地方, 一般是问数学上的东西. 
	4. 要讲清楚的是 自己做了哪些东西, 而不是自己做的这个东西是什么, 做东西, 讲故事.
	5. PPT 论文内容 论文题目, 要对应.
	6. 临场的PPT其实发挥不回来什么效果, 专家看的一般是实验设计是否完备, 基础的指标是否了解, 是否有没有出现基础的失误.
	7. 不知要用性质上说明问题, 还需要数字.
	8. 作图 表 都有一定的规范, 要遵守它
	9. 做的事情要从数学上懂得它, 不然很容易被问住.	
3. 改网络结构, 争取超过它.





2023.5.28
1. 布置会场
2. 参加师兄预答辩

2023.5.27
1. 等待加入香草网络的backbone训练完成, 因为网络中的激活值随着epoch的增长变化, 最终归0, 所以需要等到整个网络训练结束才能知道最终效果, 很有可能出现loss在后续的epoch中不断升高的现象.
2. CET6, 先把所有的单词过一遍, 之后把课程刷完, 做好笔记, 之后开始刷题, 从上一次的教训看来, 主要的短板在写译上, 应该早点准备.
3. FPGA的板子, 先放一放, 等六级复习步入正轨在开始调.



2023.5.26
1. 发现昨天的分析有问题, 虽然正负样本差距过大, 但是损失取得是正负样本loss的平均值, 所以更改权重后, 网络真的对正样本过拟合了.
2. 当shift调整至16 / 32., 网络在进行多个epoch训练后, 有拟合的迹象, 如shift = 16, 在第25个epoch, loss降为0.37, shift = 32, 在第32个epoch, loss降为0.42	
3. 可以证明, 当shift移动过大时, 网络缺乏拟合能力, 不能收敛, 有两种解决方法, 一种是增加padding, 加深网络深度, 增加网络非线性能力,这是之前的主流观点.
	另一种是, 使用香草网络的结构, 多个损失函数相结合, 竖直方向融合网络, 初步已经证明可用
4. 决定将香草网络的结构融合进RepVGG, 增加backbone的非线性能力.												(完成)



2023.5.25
1. ln(0.5) = 0.69, 当前损失0.67, 目前看, 负样本和正样本数量差距过大, 正样本数量占总量0.05, 负样本数量占0.95, 网络对负样本过拟合了, 输出全部为0, 导致损失在0.67附近徘徊.  (完成, 失败了)
   重新设计损失函数匹配, 正样本权重提高为0.95, 负样本权重降为0.05(原本是0.5 / 0.5)					(完成, 失败了)
2. 重新训练 shift = 64 的模型												(完成, 失败了)
3. 看新的backbone的论文, 能不能尝试着把它的损失函数运算策略拿来用.							(完成, 有希望)



2023.5.24 结果与分析
backbone: MobileONE, 仅回归 cls 分支:  (主要测试 MobileOne 这个架构是否有收敛能力)
	1. shift = 0, cls loss在第5个epoch为: 0.43
	2. shift = 64, cls loss在第5个epoch为: 0.67
	3. shift = 16, cls loss在第25个epoch为: 0.37
	4. shift = 32, cls loss在第32个epoch为: 0.42
	网络是否收敛, 和shift有关, shift越大, 越需要网络的非线性能力, 但是浅层网络的非线性能力较差, 
	在跟踪领域, 大家为了解决这个问题, 采用的方式都是增加网络的深度, 加入padding, 同时也就有了shift来缓解padding带来的平移不变形的损失. 
	另一方面, 即使没有平移不变形的损失, 由于后面的网络都需要回归目标的大小信息, 
	在训练机制上如果没有shift, 目标只会落在特征图的中心位置, 尺度回归的网络会对中心的几个点过拟合, 也需要引入shift来缓解这种过拟合现象, 
	之所以使用了ocean的大体结构, 但是自己的网络效果那么差, 就是因为backbone太浅了, 无法收敛, 所以对应的将shift调小, 
	结果尺度回归过拟合了,出现了越不使用网络提供的尺度信息,跟踪的性能越好的奇怪现象.
	
	
	
	
	

2023.5.24
1. 似乎找到了效果不好的根源, 可能是因为 shift 太小了,导致网络加入padding后找到了基本的规律, 就像是掉到了siamrpn的坑里...			(完成)
2. 那么下一步要做的事情是: 将shift调整成64, 同时保证网络收敛, 首先要让分类分支收敛, 这个要依赖RepVGG, 先仿照SiamDW的backbone写成RepVGG的形式, 然后不进行回归分支的损失计算, 看分类分支是不是可以收敛.																	(完成, 彻底不能拟合)
3. 很久之前做过RepVGG的实验, 当时没有收敛, 找一下缘由												(实验数据丢失)
4. 分类分支收敛后, 重新对分类损失和回归损失进行训练, 回归损失的计算方式是: iou = e^(-loss), loss 降到 0.2 的时候, Iou几乎已经在80%了, 相当高的分数		(未完成, 目前未收敛)
5. 新冠复阳了, 回宿舍修养两三天.														
6. 训练一个SiamFC的更简单的版本, 只回归目标的大小, 这样用到的参数量会更少, 如果做得好, 可以在发一篇论文, 加入硬件的话, sci4区应该没问题.	
7. 还有一些训练好的数据, 还没有进行实验, 列在下方
	1. 纯siamfc, 无尺度变化, 记录fps.													(未完成)
	2. siamfc + 尺度变化, 但是只改变大小, 如 *1.03或者 *0.975										(未完成)
	3. 解释为什么目前的anchor free 无尺度变化反而成功率大幅上升 (padding)									(似乎, 因为backbone没有padding, 所以对目标位置的判断还是正常的, 只是尺度不正常, 所以去掉尺度的因素后, 性能上升)
	4. 测试当前正在运行的网络(search 抽取特征后,在某个阶段和互相关的图相乘,直觉上感觉不行,因为 padding)					(未完成, 前面的步骤出问题)
	5. 去掉padding, 再次训练, 看网络是否可以收敛, 并记录效果如何										(未完成, 前面的步骤出问题)
	6. 不去掉padding, shift增加到64, 弄一个可以收敛的网络											(未完成, 前面的步骤出问题)
	7. 完全换成ocean的架构, 先互相关,shift = 64, 用互相关的图来进行尺度回归								(未完成, 前面的步骤出问题)
	


2023.5.23
1. 看一下延长backbone之后的性能如何, 目前看起来不是很行...					(完成)
2. 训练相乘版本										(完成)
3. 看一下 shift=16, 分类是否可以收敛								(完成)
4. 写专利											(写了一部分了,换到ubuntu系统后又放下了)

2023.5.22
1. 延长回归的backbone，增加参数量和计算量，观察是否可以收敛					(收敛了, 但是性能极低)
2. 发现一个很有意思的事情：在当前架构下（分类的特征图和回归的特征图会有一个相乘的操作），只使用回归的损失作反响传播，那么分类的损失也会下降，而且降的不算慢，也许这代表着特征图中确实存在着一些尺度信息，分类的分支也会使用尺度信息作回归。					


2023.5.21
1. 研究fcos，发现参数量很大，看了运行机制，看是否可以稍作删减，运行在siamfc上，性能都是用参数堆起来的。



2023.5.20
1. 很具有嘲讽性的结果:增加3个3*3卷积后，成功率是0.307，准确率是0.405，如果将回归分支去掉，全部用初始的大小，成功率会增加到0.398，准确率会增加到0.531. 目前网络速度相当快，已经在500FPS上下波动了，当网络跟踪失败，fps会显著下降，这个应该操心一下，说不定可以用来作为SVM的代替版。	(resize有问题, 在某种情况下,它会耗费比卷积更多的时间,换到GPU上,或者向其他办法,可以显著增加网络速度)
2. 如果不加这三个3*3卷积，0.162 / 0.232，似乎增加卷积还是比较有用的...  没有最差，只有更差呀... (数据丢失了)
3. 下一步的计划：
	目前看有三个选择：
		1. 学习ocean，将两个特征图互相关之后进行卷积，看结果						(可以试试)
		2. 借鉴FCOS，将网络加深，做成一个分支暹罗，一个分支检测，害怕这个需要很深的网络		(暂时搁置, 参数量过大, 可以学习一点点)
		3. 继续在现有的网络上进行加深，同时不对分类分支进行回归，观察网络是否收敛，收敛的值应该在0.1 - 0.2 之间，验证收敛之dancer2后，再次进行整个网络回归，并测试。(完成, 实验失败)
		4. 记得看一下是不是分类分支过拟合了。								(未完成)
	三个东西同时搞
4. 快考六级了，以后晚上的时间用来学六级。									(为完成)
5. 将师弟添加到github群组中。											(完成)
6. 将tello的项目添加到github中。										(完成)
7. 目前网络的长时跟踪，相当差，恐怕是最差的。									(效果本就相当差)




2023.5.19
1. 参加校运会													(完成)
2. 训练并测试新的网络架构，实际上就是在回归分支上增加几个3*3卷积						(完成, 忘记了更改shift)




2023.5.18()
1. 重新写个backbone，在跑一下看看是否会收敛，或者直接用 alexnet.						(完成)
2. 重新看看基础知识，了解清楚为什么一个网络进行两次前向传播，结果会不一样，先测这个。				(还是没有弄清楚, 似乎这个现象只发生在RepVGG上)
3. 微笑活动，10:00 - 14:30，需要在外面跑。									(完成)





2023.5.17
1. 调服务器的代码，在服务器上准备数据集									(完成)
2. 单独测试分类损失，观察损失是否会降低，发现不会，并且分类+回归依旧不能收敛					

2023.5.16
1. 看一下data loader的代码											(完成)
2. 修改data loader的代码，变成完全的siamfc的代码								(完成)
3. 重新训练试试												(实验失败)


2023.5.15
1. 发现分类损失不降低，按理说应该是0.2上下，现在是0.5，在看一下训练的过程，是否有遗漏的东西。			(完成, shift太大了,网络收敛不了)
2. 现在的成功率是0.32，准确率是0.43，比人家差一半，这不行。							


2023.5.11 - 2023.5.14
1. 调训练用的代码，部署的时候 net.eval()									
2. 改写网络架构												(完成)
3. 等训练结果													(实验失败)


2023.5.10
1. 等待程序运行结果，也可先测试前面的pth					
2. 小论用《仪器仪表学报》审稿意见改造										(无法改造, )
3. 研究一下比赛的赛题选哪个？											(目前看, 效果还比较差, 无法参加)
4. 沟通数据集背景的使用											(完成)
5. yolo v5的使用/ mmdetection											(完成, 改用yolo v8)
6. 看一下程序还有哪些问题											




2023.5.9 
1. Ocean改造									√
2. 组会									老师太忙，没开
3. 小论改造，实验数据分析							(小论暂时搁置了)






2023.5.8
1. 把控制程序调好，准备记录路径						√
2. 数据集准备好								√
3. Ocean改造									太懒了




2023.5.7
1. SiamBan的修改版，写程序-跑程序-看效果，主要看昨晚想出来的架构行不行，为什么不行
2. 深入到互相关出来的数据看一下
3. cpu性能调整									√
4. 程序性能分析								√





2023.5.6
1. 看一下改进cross correlation 						√
2. 每隔epoch的pth都跑一下，写程序，这个不难					√
3. siamBAN这个是最主要的任务，看着太简单，了解一下细节				√
4. android上测试现在的backbone的时间						没时间
5. PID算法看看怎么调比较合适							交给师弟
6. 更改backbone的通道数看看效果降不降						没时间
7. 分析一下现在的速度瓶颈在哪儿						√
	实际上卷积操作只占用了25%的时间，剩下的时间主要集中在numpy.argmax、resize等操作上，这个看能不能想办法改进
8. 将互相关层放到上一阶段							√
9. 特征融合									√
10. 确定什么时候神经网络已经收敛了						√



2023.5.5
1. 查看训练进度
2. 看一下新的backbone的参数量和运算量，能在android上跑一下就更好了		√
3. 新的架构的实现，可更改的点：每层的通道数，网络的padding结构，尽快跑出结果	√ 通道数已经降低到128，再降就只能是96了，可以试试
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，cross corrolation也要升级					√ 还没有验证效果, 明天下午结果能出来个大概
5. SiamBAN的引入，anchor-free							读不懂绝对不能使用
6. vim的配置									√
总结：还没有在android上跑过，PID算法先看了一下，下个阶段是验证两种互相关的卷积方式哪一个更好一些，之后加上多个阶段的融合
      记得保存每个阶段的pth文件
;




2023.5.2 - 2023.5.4
1. 训练改进后的backbone							√
2. 来学校									√
总结：实际上是在SiamDW的基础上进行改进了，去除了1*1的通道层，增加了并行分支，identity有了新解法




2023.5.1
1. 看新疆大学的论文，并写文档汇报						√
2. 训练方法、从mobileONE迁移过来实现						√
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，corss corrolation也要升级					√
5. SiamBAN的引入，anchor-free							√
6. vim的配置
具体要做的实验：
1. 在siamfc上改backbone，用冲参数化之后的backbone作训练，先验证效果		
2. 在siamfc上实验特征融合，先不使用空洞卷集
3. 在siamfc上backbone有效果的话，用重参数化之前的backbone作训练
4. 在siamfc上实验空洞卷积特征融合
5. 在siamfc上实验ban
6. 感受野和训练数据的裁减方式做实验，看原siamfc的论文的讨论
总结：
1. 不能直接使用参数化过后的算法结构作训练，因为bn也被融合了，导致算法输出全部是0，加上bn不能保证算法相似性，只能先用大参数量跑了
2. torch.compile有问题，目前还用不了，感觉把算法全部迁移到ubuntu环境白耗心血。
3. 中期答辩的讲法：先将siamrpn++的结构，之后对三个模块进行升级，之后将部署的进展，应用的进展，最后讲接下来要做的事情
	有：	目标丢失机制的建立以及为什么能够建立
		跟踪算法的升级，PID算法
		接下来的部署平台 FPGA

		



2023.4.29
1. 新的架构设计



2023.4.28  -------------------------------------------------------->
1. 在Ubuntu上跑通nano。					√
2. 看SiamBan的论文，重新设计架构。				×
回家、跑通了nano，重新裁减了数据集  ------------------------------->  






2023.4.27  -------------------------------------------------------->
1. 项目存档，保留各个师兄师姐的代码，方便后续学习。		√
2. 在Ubuntu上跑通nano。					×
3. 看SiamBan的论文，重新设计架构。				×
4. pysot-toolkit的使用。					√
跑通了siamfc，手动降频了CPU，变得十分卡顿，不知道有没有问题，nano数据集准备需要时间，SiamBan简单一些。




2023.4.23 - 2023.4.26  -------------------------------------------->
1. Ubuntu系统安装
2. 数据集迁移


2023.4.22  -------------------------------------------------------->
1. 看一下搜参的改进有多少：似乎很少，只是提升了1个点不到，等模型稳定后在进行搜参吧，目前看应该是模型数据量太小
2. 测试新写的搜参程序：×
3. 新的backbone，现在是alexnet的改进版，下次参考HRnet来写一个新的backbone  	×
4. 写融合特征的程序										×
5. 开始新的训练										×
在OTB2015上跑了之前的程序，相当差，成功率只有0.4，不知道问题出在哪里。 ->




2023.4.21---------------------------------------------------------->
1. 安装cuda11.8 安装pytorch2.0，准备好切换的程序  	×(需要Ubuntu系统)
2.  搭建搜参的环境						未完成
3.  搜参完成后，重新看一下性能				√
4.  新的backbone搭建					×
5.  互相关的改进						×
6.  程序再次训练与调参					×
搜参用了太多时间和资源  ---------------------------------------------->  







2023.4.20
1. 先把训练结果跑出来看一下 	√
2. 看一下REP的最新论文		√
3. 搜参很重要，看一下SiamDW的搜参和nano的搜参 √
4. 跑出结果，改backbone，开始写专利
5. 互相关的操作要算一下
6. 记账				√
7. 打印跑步表格			√
8. SVM的常用包看一下资料，准备SVM的数据


2023.4.13

center map √
keep point √
focus√


2023.4.12
1. 研究一下为什么SiamRPN那么快，它的骨干网络是什么，网络参数量和运算量分别是多少
	SiamRPN使用的是alexnet的骨干网络，没有采用padding，所以更快一些，RPN机制保证了框的准确性，换成anchor-free之后，最终在OTB2015上的成功率只有0.52，虽然很快，但是还没有SiamFC快。
2. 研究一下anchor free的tracker，先移过来。
3. RepVGG，把 MobileONE 的训练技巧复现一下。
4. 迅速将anchor free部署到Android，在原有的架构上改进。
   先做第二点，看一下ocean.
结果：
1. 跑通了trackit的测试代码，得到了Ocean的结构
2. 试着用anchor的尺寸作为卷积的尺寸进行特征提取
3. 






框架的要求
1. 支持测试的数据集：OTB、got10k、VOT数据集测试程序的编写，要有FPS。
    支持训练的数据集：VID、COCO、got10k，测试和训练分开。
2. 神经网络参数量测量程序的编写。
3. 各数据集的读取，以及dataloader的编写。
4. 激活函数换成ReLU6。
5. backbone、RPN、在这中间，应该使用注意力机制来搞，要思考如何将这些提取到的特征更高效的运用起来。
6. 硬件移植，先搞edgeboard和K510，来年Jetson orin nano发布之后，如果能买到，使用orin nano进行部署。
7. lighttracking、FEAR-L、FEAR-XS、FEAR-M、Ocean（Offline）、STARK（S-50）、SiamFC++（AlexNet）、SiamFC++（GoogleNet）、
	SiamRPN++（mobileNet-v2）、SiamRPN++（ResNet-50）的实现，并且整合到框架中，而不是多个项目工程同时跑数据、LightTrack、STARK（Lighting）
8. Efficient-net、mobile-net v2、RepVGG的训练方式、MobileOne的组织结构，都要学一下。
9. 要有logging，要有断点续训，不需要分布式，针对不同的算法要生成不同的文件夹来存放数据，不然每次要改就很烦。
10. 测试工具：vot toolkit   pysot toolkit  vot toolkit


要尽量使用别人写好的代码，而不要试图自己去写完所有的代码，最好找已经存在的库来做。


1. 尽量少的分支
2. 尽量少的分组
3. 尽量使用3*3卷积
4. 输入通道和输出通道尽可能一致
5. 尽量少的element操作
6. 目标是尽量少的参数量 + 尽量少的MAC



