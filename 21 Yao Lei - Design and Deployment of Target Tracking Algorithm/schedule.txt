2023.x.xx  -------------------------------------------------------->




xxxxxxxxxxxxxxxxxxxx  --------------------------------------------->  
2023.5.5
1. 查看训练进度
2. 看一下新的backbone的参数量和运算量，能在android上跑一下就更好了
3. 新的架构的实现，可更改的点：每层的通道数，网络的padding结构，尽快跑出结果
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，cross corrolation也要升级
5. SiamBAN的引入，anchor-free
6. vim的配置									√



2023.5.2 - 2023.5.4
1. 训练改进后的backbone							√
2. 来学校									√


2023.5.1
1. 看新疆大学的论文，并写文档汇报						√
2. 训练方法、从mobileONE迁移过来实现						√
3. 新的训练数据集加入，LaSOT
4. 验证backbone之后，corss corrolation也要升级
5. SiamBAN的引入，anchor-free
6. vim的配置
具体要做的实验：
1. 在siamfc上改backbone，用冲参数化之后的backbone作训练，先验证效果		
2. 在siamfc上实验特征融合，先不使用空洞卷集
3. 在siamfc上backbone有效果的话，用重参数化之前的backbone作训练
4. 在siamfc上实验空洞卷积特征融合
5. 在siamfc上实验ban
6. 感受野和训练数据的裁减方式做实验，看原siamfc的论文的讨论
总结：
1. 不能直接使用参数化过后的算法结构作训练，因为bn也被融合了，导致算法输出全部是0，加上bn不能保证算法相似性，只能先用大参数量跑了
2. torch.compile有问题，目前还用不了，感觉把算法全部迁移到ubuntu环境血亏。
3. 中期答辩的讲法：先将siamrpn++的结构，之后对三个模块进行升级，之后将部署的进展，应用的进展，最后讲接下来要做的事情
	有：	目标丢失机制的建立以及为什么能够建立
		跟踪算法的升级，PID算法
		接下来的部署平台 FPGA

		



2023.4.29
1. 新的架构设计



2023.4.28  -------------------------------------------------------->
1. 在Ubuntu上跑通nano。					√
2. 看SiamBan的论文，重新设计架构。				×
回家、跑通了nano，重新裁减了数据集  ------------------------------->  






2023.4.27  -------------------------------------------------------->
1. 项目存档，保留各个师兄师姐的代码，方便后续学习。		√
2. 在Ubuntu上跑通nano。					×
3. 看SiamBan的论文，重新设计架构。				×
4. pysot-toolkit的使用。					√
跑通了siamfc，手动降频了CPU，变得十分卡顿，不知道有没有问题，nano数据集准备需要时间，SiamBan简单一些。




2023.4.23 - 2023.4.26  -------------------------------------------->
1. Ubuntu系统安装
2. 数据集迁移


2023.4.22  -------------------------------------------------------->
1. 看一下搜参的改进有多少：似乎很少，只是提升了1个点不到，等模型稳定后在进行搜参吧，目前看应该是模型数据量太小
2. 测试新写的搜参程序：×
3. 新的backbone，现在是alexnet的改进版，下次参考HRnet来写一个新的backbone  	×
4. 写融合特征的程序										×
5. 开始新的训练										×
在OTB2015上跑了之前的程序，相当差，成功率只有0.4，不知道问题出在哪里。 ->




2023.4.21---------------------------------------------------------->
1. 安装cuda11.8 安装pytorch2.0，准备好切换的程序  	×(需要Ubuntu系统)
2.  搭建搜参的环境						未完成
3.  搜参完成后，重新看一下性能				√
4.  新的backbone搭建					×
5.  互相关的改进						×
6.  程序再次训练与调参					×
搜参用了太多时间和资源  ---------------------------------------------->  







2023.4.20
1. 先把训练结果跑出来看一下 	√
2. 看一下REP的最新论文		√
3. 搜参很重要，看一下SiamDW的搜参和nano的搜参 √
4. 跑出结果，改backbone，开始写专利
5. 互相关的操作要算一下
6. 记账				√
7. 打印跑步表格			√
8. SVM的常用包看一下资料，准备SVM的数据


2023.4.13

center map √
keep point √
focus√


2023.4.12
1. 研究一下为什么SiamRPN那么快，它的骨干网络是什么，网络参数量和运算量分别是多少。
2. 研究一下anchor free的tracker，先移过来。
3. RepVGG，把 MobileONE 的训练技巧复现一下。
4. 迅速将anchor free部署到Android，在原有的架构上改进。
   先做第二点，看一下ocean.
结果：
1. 跑通了trackit的测试代码，得到了Ocean的结构
2. 试着用anchor的尺寸作为卷积的尺寸进行特征提取
3. 






框架的要求
1. 支持测试的数据集：OTB、got10k、VOT数据集测试程序的编写，要有FPS。
    支持训练的数据集：VID、COCO、got10k，测试和训练分开。
2. 神经网络参数量测量程序的编写。
3. 各数据集的读取，以及dataloader的编写。
4. 激活函数换成ReLU6。
5. backbone、RPN、在这中间，应该使用注意力机制来搞，要思考如何将这些提取到的特征更高效的运用起来。
6. 硬件移植，先搞edgeboard和K510，来年Jetson orin nano发布之后，如果能买到，使用orin nano进行部署。
7. lighttracking、FEAR-L、FEAR-XS、FEAR-M、Ocean（Offline）、STARK（S-50）、SiamFC++（AlexNet）、SiamFC++（GoogleNet）、
	SiamRPN++（mobileNet-v2）、SiamRPN++（ResNet-50）的实现，并且整合到框架中，而不是多个项目工程同时跑数据、LightTrack、STARK（Lighting）
8. Efficient-net、mobile-net v2、RepVGG的训练方式、MobileOne的组织结构，都要学一下。
9. 要有logging，要有断点续训，不需要分布式，针对不同的算法要生成不同的文件夹来存放数据，不然每次要改就很烦。
10. 测试工具：vot toolkit   pysot toolkit  vot toolkit


要尽量使用别人写好的代码，而不要试图自己去写完所有的代码，最好找已经存在的库来做。


1. 尽量少的分支
2. 尽量少的分组
3. 尽量使用3*3卷积
4. 输入通道和输出通道尽可能一致
5. 尽量少的element操作

6. 
 目标是尽量少的参数量 + 尽量少的MAC


SiamDW
1. 步长 4 / 8
2. 最终感受野 80%
3. 无padding


输入 127*127 的图片
1. 一个 3*3 无padding的影响
	一个点是3
2. 两个 3*3 
	一个点是

3*3		3
3*3		
3*3
3*3
3*3
3*3
3*3		
3*3		3
