2023.x.xx  -------------------------------------------------------->
xxxxxxxxxxxxxxxxxxxx  --------------------------------------------->  

TODO
1. 师兄的小论发表
2. 网络训练
3. 比赛
4. 贾鹏老师的火箭跟踪










2023.7.28
1. nanotrack使用MobileONE收敛到0.18就不再向下收敛了， SiamRPN使用resnet22收敛到0.5就不再收敛了。
2. 需要更好的训练策略，最好把MobileONE的直接拿来用，一会儿去调一下。
	要写很多新东西，之前没见过的东西。开始使用git管理版本。
3. 直接使用nanotrack的Android代码，测一下mobileone在手机端的运行速度。
4. 写测试代码，看mobileone在dtb上的性能。
	test.pth VOT2018  lr-0.39  pk-_0.148  win-_0.462
	------------------------------------------------------------
	|Tracker Name| Accuracy | Robustness | Lost Number |  EAO  |
	------------------------------------------------------------
	|   TESTR0   |  0.565   |   0.445    |    95.0     | 0.265 |
	------------------------------------------------------------

	Nanotrack
	------------------------------------------------------------
	|Tracker Name| Accuracy | Robustness | Lost Number |  EAO  |
	------------------------------------------------------------
	| NanoTrack  |  0.542   |   0.328    |    70.0     | 0.311 |
	------------------------------------------------------------
	好怪异的结果，Accuracy和Robustness都比较高，EAO和 Lost Number居然比较低，先写一个搜参程序，试试咋样，0.265太低了。
5. 将resnet22去掉一层，重新使用got10k 600000训练，使用服务器，希望它可以接着收敛，实在不行，再看一下nanotrack的训练策略，将这个策略运用到resnet22上。
6. mobileOne是否可以接着降低参数，通道数和网络深度 看可不可以降。
7. 理论上，使用多个数据集同时训练，可以提升模型3.5%左右的auc，这一点适用于两个模型。
8. mobileone的互相关，是不是可以换成别的。
9. resnet22可不可以写成rep的形式，看一下是不是可以提升效率。


2023.7.27
1. 新的网络架构 骨干网络 -> rpnhead 训练好了，成功率0.50.
2. 下一步：
	1. 使用更好的训练集训练这个模型
	2. 使用更大的backbone训练模型，看这个模型的潜力是多少，目前用AlexNet，它似乎还没还有完全收敛。
	3. 发挥出模型的潜力之后，使用mobileOne去缩小backbone的参数量和计算量，取均衡。
3. 另一个问题，似乎显卡在经过一整年的训练之后，性能下降了很多，有可能是设置的问题，目前还没有办法解决它。 
4. 使用mobileone做backbone的nanotrack，已经训练好了，准备测试。


2023.7.23
1. 先把MobileOne的基本架构弄来，然后重新训练一下看看吧。

2023.7.22
1. 重写mobileone，快速训练ocean。
2. 更换siamrpn的backbone，开始训练。
3. 目的是快速出结果，之前的想法不能实现，现在就是要一个能正常运行的结果。

2023.7.21
1. 昨天和前天看了一下Ocean原生的网络模型的训练时候的情况，分类损失已经降到了0.06，回归损失降到了0.14，网络层数深带来的拟合性是浅层网络达不到的。
2. 暂时放弃之前的想法，先把siamRPN和nanotrack换一换backbone，重新训练一下看看效果。
3. Ocean 或许不应该训练backbone，只训练head说不定都会更好一点。
4. 今天的几个任务：
	1. nanotrack跑通
	2. siamrpn跑通
	3. 两个模型换backbone
	4. 重写VGG类型的mobileone，放到Ocean上进行训练。

2023.7.18
1. backbone换成 MobileOne， 进行训练
2. 找center ness的bug，收敛不了，不知道为什么。


2023.7.17
1. 测试，用新的数据集跑了50个epoch， 
	CLS_ORI Loss:0.17050
	REG Loss:0.11369
	Loss:0.28419
	结果：0.2，还是很差，为什么相同的架构，我的网络结果就这么差呢？
		还是老老实实的把ocean写出来，训练一下看看吧...
2. 使用点卷积，将特征图的尺寸提升到 21 * 21 之后， 
		|        OceanT21        |  0.346  |     0.000      |   0.501   |
		还是很差，相对于 17 * 17 的时候，成功率提升了5%
3. 使用stride = 4的backbone，特征图尺寸是33 * 33：
		
4. 对center ness分支分析，目前写的东西，无法收敛，有问题。
	看完了meta实现的fcos，并没有什么差别，我不能理解为什么无法收敛，最终center ness收敛值为0.5，我认为至少应该在0.2以下。

5. 使用mobileone写一个跟踪器， stride = 8， 加入裁剪的因素， 特征图的大小为 25 * 25. 重新训练。
	# [1 3 255 255] -> [1, 128, 32, 32]
	# [1 3 127 127] -> [1, 128, 16, 16]
	# crop [16 - 8] -> 8       32 - 8 + 1 = 25, 25*25
	# 加入center ness分支的siamfc可以预见的效果不太好，先把mobileone的前三层送到ocean尝试一下。


2023.6.30 - 2023.7.1
1. 尝试复现SiamDW
2. 学习 rt-thread


2023.6.29
1. 使用相同的训练方法，使用相同的网络架构，无法重现SiamDW的结果。
2. 可以直接使用原有的pth和架构，迅速搭建出anchor free的架构来进行跟踪。

2023.6.28
1. 有如下结论，
	不同的网络结构对应着不同的超参数，超参数的寻找很重要
	同一个网络结构的不同pth，使用的超参数应该是一样的，如ResNet22W，官方给出的最优解是0.6589，使用不同的Pth去做测试，得到的最好结果是0.647，相差0.011，也就是说，寻找超参数的过程如下：
	1). 先写好网络，进行训练，得到50个pth文件
	2). 将50个pth文件使用寻常的超参数进行测试，得到结果最好的那一个。
	3). 将结果最好的那一个，使用搜参算法寻找超参数，直到网络收敛。
	4). 使用寻找到的超参，对50个pth进行测试，找到最好的那一组结果。

	网络的预权重很重要，找到可以使用的网络预权重重新进行训练试试。

2. 现在有如下困惑：
	1). 为什么SiamDW给出的pth是33，但是它的损失还是0.14，看现在情况，第33个epoch早都已经过拟合了，损失应该在0.1以下。

3. 现在的任务
	1) 继续尝试复现SiamDW
	2) 使用MobileOne重新训练一个SiamBAN，试一下看看效果。

2023.6.27
1. 等待SiamDW训练完成

2023.6.26
1. 尝试复现SiamDW的训练过程

2023.6.25
1. 他们可能使用了很大的数据集，导致网络在第33个epoch损失值已经下降到了0.14.
2. 目前最关键的是找到他们挑选pth的方法。如果用到了很大的数据集 + 对每一个epoch产生的模型进行测试 + 搜参，那么需要很大的算力。
3. 尝试复现SiamDW，看一下标准的训练过程是怎么样的。


2023.6.24
1. 写了ray和gene的搜参算法，调试好了软件包。
2. 配置了pysot环境

2023.6.23
1. 运行siamdw原始程序，训练到了第38个epoch，发现损失到达0.17，不在下降
2. 重新使用siamdw给出的pth进行训练，发现他们选择了第33个epoch的pth，此时损失值在0.14。


2023.6.19 - 2023.6.22
1. 尝试恢复原来的系统，失败。
2. 重新安装Windows10系统。


2023.6.18
1. 电脑坏掉了，具体原因如下：
	为了写搜参算法，需要用到ray程序包
	ray包不能正常运行，怀疑是显卡驱动和cuda不匹配
	重装cuda，对齐驱动和cuda版本，对齐后发现屏幕亮度保持最亮，无法调节
	查资料发现是Ubuntu kernel与笔记本电脑不匹配
	重装Ubuntu kernel，但是由于kernel head无法编译，导致系统崩溃，无法安装新的程序
	备份Ubuntu资料后，使用rm -rf /* 来删除系统
	rm -rf /*直接将Windows引导也删掉了，两个系统都无法进入，只好全部重装
		

2023.6.15 - 2023.6.17
1. 参加六级考试

2023.6.11 - 2023.6.14
1.准备数据，参加中期答辩
	
2023.6.8 - 2023.6.10
1. 准备各个版本的程序, 跑出结果, 中期答辩用
2. 英语, 作题




2023.6.7
1. 准备中期报告, 不再向前探索, 先跑出中期要用的数据, 如下:
	1. 找一台服务器，跑ocean的原生训练过程，观察损失的变化，以及最后收敛到哪里，shift=64.
	2. 找siamdw，这应该是跑的最好的Siamfc，直接将最准确的大小信息输入进去，看成功率如何。
	3. 找服务器，在siamdw的基础上更改backbone，观察效果，先加rep训练
	4. 找服务器，在siamdw的基础上改backbone，观察效果，加上repvgg vainilla net，shift 一律4
	5. 再试一下label的更改，观察是否对输出有提升。
	6. 希望可以尽快出成果，这一次直接加载训练好的backbone，训练后面的几个卷积层，问题在于解决跟踪器的问题
2. 准备中期PPT
3. 跟老师汇报最近的进度
数据: siamfc使用新的架构之后, 使用bounding box的size, 最好的结果可以达到0.697的跟踪成功率, lighttrack的成功率是0.59, 
	

2023.6.6
1. 等待网络收敛, 观察效果													(效果大致只能到0.56, 不好, 换回原有的label重新训练)
2. CET6															(完成)
3. 从训练过程中来看, 加上hanning窗之后, 预测值最大的点与实际上最大的点总是相差5个单位的距离, 这需要在找一找原因, 尤其是不管网络是否收敛, 总能相差5个单位有点奇怪, 如果能把这个东西搞清楚, 那么说不定可以提出对应的解决策略.



2023.6.5
1. CET6															(完成)
2. 总结比赛															(完成)
3. 测试新的网络能力														(完成)
总结:    
    将特征图resize为255 * 255, 与真正的label进行损失函数计算, 网络的性能下降了, 在训练中, 网络的损失收敛到 0.28 不再向下收敛, 有两种解决方法:
	1. 使用新的backbone, 观察是否可以收敛的更好										(依旧收敛到0.27左右, 感觉新的backbone似乎也就那样...)
	2. 将特征图变小, 重新计算损失, label依旧是梯度下降									(在进行尝试)


2023.6.4
1. 距离损失无法进行反向传播, 重新设计损失函数, 将距离的损失加入到lebel中, 使得更有非线性的网络更能发挥自己的能力.		(完成)



2023.6.3
. 调两阶段训练的代码														(完成)
2. 坑: 在stage2中, 固定backbone参数的时候, 没有固定bn层的参数, 导致训练过程中网络的bn层一直在进化, 结果每个conv层输出的结果不一样, 找bug, 很久.	(完成)
3. 将跟踪分成两个部分, 分别是分类和回归, 分类主要预测物体的位置信息, 回归预测物体的大小信息, 这两个部分单独进行测试, 使用gt中的target size, 使用cross corralation得到分类图. (完成)
4. 假设有一个完美的跟踪器可以得到目标的尺度信息, 最后的成功率可以达到0.659, 准确率可以达到0.796, 这说明互相关机制还不能很好的结果目标位置的问题.
5. 由于将分类分支用于目标的位置回归, 所以考虑加入距离的损失, 也就是说, 对于分类分支有如下几个优化:
	1. 损失函数 + FCOS类似的距离损失.											(距离损失无法反向传播, 失败)
	2. 网络的架构, 从alexnet转换成siamdw的bacobone.									(完成)
	3. 网络块, 使用 RepVGG 和 香草网络相融合的形式, 探索更好的性能.							(完成)
6. 今天先写好FCOS类似的新的损失函数, 看怎么设计比较好一下. 具体的讲, 为了更贴合实际的预测过程, 不再使用17 * 17的特征图计算分类损失, 而是将17*17的特征图resize为(17*16) * (17*16)的特征图, 与276 * 276 的标签计算分类损失, 另外, 在272*272上找到最大值的点, 计算最大值的点相对于中心点的距离, 将这个距离作为损失的一部分加入进去, 看一下分类分支会不会有大的变化, 或者直接在生成一个272*272的图.															(效果变差, 失败, 未找到原因)




2023.6.2
1. 加入VanillaNet之后, 由于激活函数在训练过程中会发生变化, 再加上横向和纵向对网络的扩展, 网路训练一次需要两天, 效果出的太慢了.
2. 重写一套程序, 仅使用简单的siamfc作为主体框架, 先完成训练, 需要重写 dataloader  网络结构  前向传播等等.			(完成)
3. 將resize写道cuda里, 增加网络速度, 之后可以jetson nano测试, 有一个四区的杂志接收.	


2023.6.1
1. 重点训练集表现正常, 测试集特征层最外层数值很大的问题.
2. 去掉多层的激活函数, shift=32重新训练.
3. 重写 dataloader, 去掉随机的shift这个因子, 扩大网络搜索范围.
4. 在 shift = 64, 去掉多层激活函数的情况下, 训练15个epoch, 网络收敛不了
5. 去掉多层激活函数的情况下, shift = 32,网络似乎依旧无法收敛, 尝试在backbone中加入有限 3*3 padding = 1的卷积, 在进行尝试.
6. VanillaNet的激活函数看起来似乎仅仅是在每个relu后面跟了一个N * N的卷积, 增加了网络计算参数, 带来了非线性性能, 但是不适合无padding的跟踪.
7. 目前来看, 无padding的backbone似乎不可能实现, 是一个两难的现状:
	a. 全部使用无padding的网络, 这样限制shift < 16, 首先不能确定回归分支是否可以收敛, 无paadding, 分类分支只能使用三层.
	b. 使用有padding的网络, 不对shift进行限制, 直接拉长为64.
	c. 实际上, 分类分支需要padding的限制, 回归分支不受padding的限制, 可以分别训练, 第一阶段训练分类分支, shift = 16, 第二阶段固定backbone的参数,, shift = 64对回归分支进行训练, 可以再加一些卷积, 促进它的收敛, 实际上两个过程中不一样的东西是shift.
8. 先试一下两阶段训练, 第一个阶段shift = 16, 学一些如何两个阶段分别训练不同的参数
    
    TODO:  现在开始训练第一阶段, 位置不回归.
    	   stage 2: 先加载之前训练的部分, lr 不更改, 更改 param 的设置, 将connect的可训练参数写到优化器中, 重新进行训练






2023.5.31
1. 等待程序跑出结果, 并测试
2. 找EI会议, 改论文, 投稿
3. 写六级的卷子
4. 如有可能, 将resize的操作写到cuda里, 看是否可以增加网络速度.
实验记录: 从没见过这么差的性能, 而且还有很诡异的现象, shift = 32, 训练集跑出的特征图完全正常, 测试集上特征图的最外层的数值相当大, 查了一晚上, 没有什么发现, 预测如果将新的激活函数去掉会好一些, 但是这是为什么呢? 因为shift没有到达64吗? 其他人所有的卷积都加了padding, 也没有出什么问题, 为什么这个网络这么奇怪呢。我对于跟踪网络的理解还是比较浅。




2023.5.30
1. 身体不适, 等待电脑跑出结果.



2023.5.29
1. 参加师兄答辩
2. 经验如下:
	1. 专家看文件的顺序: 盲审结果 -> 自己写的评语 -> 成果 -> 摘要 -> 目录 -> 随便翻一翻.
	2. 专家在说话的时候, 不要抢话, 很容易让人家故意要问倒你.
	3. 专家知道整个毕业论文的目录在什么地方, 一般是问数学上的东西. 
	4. 要讲清楚的是 自己做了哪些东西, 而不是自己做的这个东西是什么, 做东西, 讲故事.
	5. PPT 论文内容 论文题目, 要对应.
	6. 临场的PPT其实发挥不回来什么效果, 专家看的一般是实验设计是否完备, 基础的指标是否了解, 是否有没有出现基础的失误.
	7. 不知要用性质上说明问题, 还需要数字.
	8. 作图 表 都有一定的规范, 要遵守它
	9. 做的事情要从数学上懂得它, 不然很容易被问住.	
3. 改网络结构, 争取超过它.





2023.5.28
1. 布置会场
2. 参加师兄预答辩

2023.5.27
1. 等待加入香草网络的backbone训练完成, 因为网络中的激活值随着epoch的增长变化, 最终归0, 所以需要等到整个网络训练结束才能知道最终效果, 很有可能出现loss在后续的epoch中不断升高的现象.
2. CET6, 先把所有的单词过一遍, 之后把课程刷完, 做好笔记, 之后开始刷题, 从上一次的教训看来, 主要的短板在写译上, 应该早点准备.
3. FPGA的板子, 先放一放, 等六级复习步入正轨在开始调.



2023.5.26
1. 发现昨天的分析有问题, 虽然正负样本差距过大, 但是损失取得是正负样本loss的平均值, 所以更改权重后, 网络真的对正样本过拟合了.
2. 当shift调整至16 / 32., 网络在进行多个epoch训练后, 有拟合的迹象, 如shift = 16, 在第25个epoch, loss降为0.37, shift = 32, 在第32个epoch, loss降为0.42	
3. 可以证明, 当shift移动过大时, 网络缺乏拟合能力, 不能收敛, 有两种解决方法, 一种是增加padding, 加深网络深度, 增加网络非线性能力,这是之前的主流观点.
	另一种是, 使用香草网络的结构, 多个损失函数相结合, 竖直方向融合网络, 初步已经证明可用
4. 决定将香草网络的结构融合进RepVGG, 增加backbone的非线性能力.												(完成)



2023.5.25
1. ln(0.5) = 0.69, 当前损失0.67, 目前看, 负样本和正样本数量差距过大, 正样本数量占总量0.05, 负样本数量占0.95, 网络对负样本过拟合了, 输出全部为0, 导致损失在0.67附近徘徊.  (完成, 失败了)
   重新设计损失函数匹配, 正样本权重提高为0.95, 负样本权重降为0.05(原本是0.5 / 0.5)					(完成, 失败了)
2. 重新训练 shift = 64 的模型												(完成, 失败了)
3. 看新的backbone的论文, 能不能尝试着把它的损失函数运算策略拿来用.							(完成, 有希望)



2023.5.24 结果与分析
backbone: MobileONE, 仅回归 cls 分支:  (主要测试 MobileOne 这个架构是否有收敛能力)
	1. shift = 0, cls loss在第5个epoch为: 0.43
	2. shift = 64, cls loss在第5个epoch为: 0.67
	3. shift = 16, cls loss在第25个epoch为: 0.37
	4. shift = 32, cls loss在第32个epoch为: 0.42
	网络是否收敛, 和shift有关, shift越大, 越需要网络的非线性能力, 但是浅层网络的非线性能力较差, 
	在跟踪领域, 大家为了解决这个问题, 采用的方式都是增加网络的深度, 加入padding, 同时也就有了shift来缓解padding带来的平移不变形的损失. 
	另一方面, 即使没有平移不变形的损失, 由于后面的网络都需要回归目标的大小信息, 
	在训练机制上如果没有shift, 目标只会落在特征图的中心位置, 尺度回归的网络会对中心的几个点过拟合, 也需要引入shift来缓解这种过拟合现象, 
	之所以使用了ocean的大体结构, 但是自己的网络效果那么差, 就是因为backbone太浅了, 无法收敛, 所以对应的将shift调小, 
	结果尺度回归过拟合了,出现了越不使用网络提供的尺度信息,跟踪的性能越好的奇怪现象.
	
	
	
	
	

2023.5.24
1. 似乎找到了效果不好的根源, 可能是因为 shift 太小了,导致网络加入padding后找到了基本的规律, 就像是掉到了siamrpn的坑里...			(完成)
2. 那么下一步要做的事情是: 将shift调整成64, 同时保证网络收敛, 首先要让分类分支收敛, 这个要依赖RepVGG, 先仿照SiamDW的backbone写成RepVGG的形式, 然后不进行回归分支的损失计算, 看分类分支是不是可以收敛.																	(完成, 彻底不能拟合)
3. 很久之前做过RepVGG的实验, 当时没有收敛, 找一下缘由												(实验数据丢失)
4. 分类分支收敛后, 重新对分类损失和回归损失进行训练, 回归损失的计算方式是: iou = e^(-loss), loss 降到 0.2 的时候, Iou几乎已经在80%了, 相当高的分数		(未完成, 目前未收敛)
5. 新冠复阳了, 回宿舍修养两三天.														
6. 训练一个SiamFC的更简单的版本, 只回归目标的大小, 这样用到的参数量会更少, 如果做得好, 可以在发一篇论文, 加入硬件的话, sci4区应该没问题.	
7. 还有一些训练好的数据, 还没有进行实验, 列在下方
	1. 纯siamfc, 无尺度变化, 记录fps.													(未完成)
	2. siamfc + 尺度变化, 但是只改变大小, 如 *1.03或者 *0.975										(未完成)
	3. 解释为什么目前的anchor free 无尺度变化反而成功率大幅上升 (padding)									(似乎, 因为backbone没有padding, 所以对目标位置的判断还是正常的, 只是尺度不正常, 所以去掉尺度的因素后, 性能上升)
	4. 测试当前正在运行的网络(search 抽取特征后,在某个阶段和互相关的图相乘,直觉上感觉不行,因为 padding)					(未完成, 前面的步骤出问题)
	5. 去掉padding, 再次训练, 看网络是否可以收敛, 并记录效果如何										(未完成, 前面的步骤出问题)
	6. 不去掉padding, shift增加到64, 弄一个可以收敛的网络											(未完成, 前面的步骤出问题)
	7. 完全换成ocean的架构, 先互相关,shift = 64, 用互相关的图来进行尺度回归								(未完成, 前面的步骤出问题)
	


2023.5.23
1. 看一下延长backbone之后的性能如何, 目前看起来不是很行...					(完成)
2. 训练相乘版本										(完成)
3. 看一下 shift=16, 分类是否可以收敛								(完成)
4. 写专利											(写了一部分了,换到ubuntu系统后又放下了)

2023.5.22
1. 延长回归的backbone，增加参数量和计算量，观察是否可以收敛					(收敛了, 但是性能极低)
2. 发现一个很有意思的事情：在当前架构下（分类的特征图和回归的特征图会有一个相乘的操作），只使用回归的损失作反响传播，那么分类的损失也会下降，而且降的不算慢，也许这代表着特征图中确实存在着一些尺度信息，分类的分支也会使用尺度信息作回归。					


2023.5.21
1. 研究fcos，发现参数量很大，看了运行机制，看是否可以稍作删减，运行在siamfc上，性能都是用参数堆起来的。



2023.5.20
1. 很具有嘲讽性的结果:增加3个3*3卷积后，成功率是0.307，准确率是0.405，如果将回归分支去掉，全部用初始的大小，成功率会增加到0.398，准确率会增加到0.531. 目前网络速度相当快，已经在500FPS上下波动了，当网络跟踪失败，fps会显著下降，这个应该操心一下，说不定可以用来作为SVM的代替版。	(resize有问题, 在某种情况下,它会耗费比卷积更多的时间,换到GPU上,或者向其他办法,可以显著增加网络速度)
2. 如果不加这三个3*3卷积，0.162 / 0.232，似乎增加卷积还是比较有用的...  没有最差，只有更差呀... (数据丢失了)
3. 下一步的计划：
	目前看有三个选择：
		1. 学习ocean，将两个特征图互相关之后进行卷积，看结果						(可以试试)
		2. 借鉴FCOS，将网络加深，做成一个分支暹罗，一个分支检测，害怕这个需要很深的网络		(暂时搁置, 参数量过大, 可以学习一点点)
		3. 继续在现有的网络上进行加深，同时不对分类分支进行回归，观察网络是否收敛，收敛的值应该在0.1 - 0.2 之间，验证收敛之dancer2后，再次进行整个网络回归，并测试。(完成, 实验失败)
		4. 记得看一下是不是分类分支过拟合了。								(未完成)
	三个东西同时搞
4. 快考六级了，以后晚上的时间用来学六级。									(为完成)
5. 将师弟添加到github群组中。											(完成)
6. 将tello的项目添加到github中。										(完成)
7. 目前网络的长时跟踪，相当差，恐怕是最差的。									(效果本就相当差)




2023.5.19
1. 参加校运会													(完成)
2. 训练并测试新的网络架构，实际上就是在回归分支上增加几个3*3卷积						(完成, 忘记了更改shift)




2023.5.18()
1. 重新写个backbone，在跑一下看看是否会收敛，或者直接用 alexnet.						(完成)
2. 重新看看基础知识，了解清楚为什么一个网络进行两次前向传播，结果会不一样，先测这个。				(还是没有弄清楚, 似乎这个现象只发生在RepVGG上)
3. 微笑活动，10:00 - 14:30，需要在外面跑。									(完成)





2023.5.17
1. 调服务器的代码，在服务器上准备数据集									(完成)
2. 单独测试分类损失，观察损失是否会降低，发现不会，并且分类+回归依旧不能收敛					

2023.5.16
1. 看一下data loader的代码											(完成)
2. 修改data loader的代码，变成完全的siamfc的代码								(完成)
3. 重新训练试试												(实验失败)


2023.5.15
1. 发现分类损失不降低，按理说应该是0.2上下，现在是0.5，在看一下训练的过程，是否有遗漏的东西。			(完成, shift太大了,网络收敛不了)
2. 现在的成功率是0.32，准确率是0.43，比人家差一半，这不行。							


2023.5.11 - 2023.5.14
1. 调训练用的代码，部署的时候 net.eval()									
2. 改写网络架构												(完成)
3. 等训练结果													(实验失败)


2023.5.10
1. 等待程序运行结果，也可先测试前面的pth					
2. 小论用《仪器仪表学报》审稿意见改造										(无法改造, )
3. 研究一下比赛的赛题选哪个？											(目前看, 效果还比较差, 无法参加)
4. 沟通数据集背景的使用											(完成)
5. yolo v5的使用/ mmdetection											(完成, 改用yolo v8)
6. 看一下程序还有哪些问题											




2023.5.9 
1. Ocean改造									√
2. 组会									老师太忙，没开
3. 小论改造，实验数据分析							(小论暂时搁置了)






2023.5.8
1. 把控制程序调好，准备记录路径						√
2. 数据集准备好								√
3. Ocean改造									太懒了




2023.5.7
1. SiamBan的修改版，写程序-跑程序-看效果，主要看昨晚想出来的架构行不行，为什么不行
2. 深入到互相关出来的数据看一下
3. cpu性能调整									√
4. 程序性能分析								√





2023.5.6
1. 看一下改进cross correlation 						√
2. 每隔epoch的pth都跑一下，写程序，这个不难					√
3. siamBAN这个是最主要的任务，看着太简单，了解一下细节				√
4. android上测试现在的backbone的时间						没时间
5. PID算法看看怎么调比较合适							交给师弟
6. 更改backbone的通道数看看效果降不降						没时间
7. 分析一下现在的速度瓶颈在哪儿						√
	实际上卷积操作只占用了25%的时间，剩下的时间主要集中在numpy.argmax、resize等操作上，这个看能不能想办法改进
8. 将互相关层放到上一阶段							√
9. 特征融合									√
10. 确定什么时候神经网络已经收敛了						√



2023.5.5
1. 查看训练进度
2. 看一下新的backbone的参数量和运算量，能在android上跑一下就更好了		√
3. 新的架构的实现，可更改的点：每层的通道数，网络的padding结构，尽快跑出结果	√ 通道数已经降低到128，再降就只能是96了，可以试试
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，cross corrolation也要升级					√ 还没有验证效果, 明天下午结果能出来个大概
5. SiamBAN的引入，anchor-free							读不懂绝对不能使用
6. vim的配置									√
总结：还没有在android上跑过，PID算法先看了一下，下个阶段是验证两种互相关的卷积方式哪一个更好一些，之后加上多个阶段的融合
      记得保存每个阶段的pth文件
;




2023.5.2 - 2023.5.4
1. 训练改进后的backbone							√
2. 来学校									√
总结：实际上是在SiamDW的基础上进行改进了，去除了1*1的通道层，增加了并行分支，identity有了新解法




2023.5.1
1. 看新疆大学的论文，并写文档汇报						√
2. 训练方法、从mobileONE迁移过来实现						√
3. 新的训练数据集加入，LaSOT							√
4. 验证backbone之后，corss corrolation也要升级					√
5. SiamBAN的引入，anchor-free							√
6. vim的配置
具体要做的实验：
1. 在siamfc上改backbone，用冲参数化之后的backbone作训练，先验证效果		
2. 在siamfc上实验特征融合，先不使用空洞卷集
3. 在siamfc上backbone有效果的话，用重参数化之前的backbone作训练
4. 在siamfc上实验空洞卷积特征融合
5. 在siamfc上实验ban
6. 感受野和训练数据的裁减方式做实验，看原siamfc的论文的讨论
总结：
1. 不能直接使用参数化过后的算法结构作训练，因为bn也被融合了，导致算法输出全部是0，加上bn不能保证算法相似性，只能先用大参数量跑了
2. torch.compile有问题，目前还用不了，感觉把算法全部迁移到ubuntu环境白耗心血。
3. 中期答辩的讲法：先将siamrpn++的结构，之后对三个模块进行升级，之后将部署的进展，应用的进展，最后讲接下来要做的事情
	有：	目标丢失机制的建立以及为什么能够建立
		跟踪算法的升级，PID算法
		接下来的部署平台 FPGA

		



2023.4.29
1. 新的架构设计



2023.4.28  -------------------------------------------------------->
1. 在Ubuntu上跑通nano。					√
2. 看SiamBan的论文，重新设计架构。				×
回家、跑通了nano，重新裁减了数据集  ------------------------------->  






2023.4.27  -------------------------------------------------------->
1. 项目存档，保留各个师兄师姐的代码，方便后续学习。		√
2. 在Ubuntu上跑通nano。					×
3. 看SiamBan的论文，重新设计架构。				×
4. pysot-toolkit的使用。					√
跑通了siamfc，手动降频了CPU，变得十分卡顿，不知道有没有问题，nano数据集准备需要时间，SiamBan简单一些。




2023.4.23 - 2023.4.26  -------------------------------------------->
1. Ubuntu系统安装
2. 数据集迁移


2023.4.22  -------------------------------------------------------->
1. 看一下搜参的改进有多少：似乎很少，只是提升了1个点不到，等模型稳定后在进行搜参吧，目前看应该是模型数据量太小
2. 测试新写的搜参程序：×
3. 新的backbone，现在是alexnet的改进版，下次参考HRnet来写一个新的backbone  	×
4. 写融合特征的程序										×
5. 开始新的训练										×
在OTB2015上跑了之前的程序，相当差，成功率只有0.4，不知道问题出在哪里。 ->




2023.4.21---------------------------------------------------------->
1. 安装cuda11.8 安装pytorch2.0，准备好切换的程序  	×(需要Ubuntu系统)
2.  搭建搜参的环境						未完成
3.  搜参完成后，重新看一下性能				√
4.  新的backbone搭建					×
5.  互相关的改进						×
6.  程序再次训练与调参					×
搜参用了太多时间和资源  ---------------------------------------------->  







2023.4.20
1. 先把训练结果跑出来看一下 	√
2. 看一下REP的最新论文		√
3. 搜参很重要，看一下SiamDW的搜参和nano的搜参 √
4. 跑出结果，改backbone，开始写专利
5. 互相关的操作要算一下
6. 记账				√
7. 打印跑步表格			√
8. SVM的常用包看一下资料，准备SVM的数据


2023.4.13

center map √
keep point √
focus√


2023.4.12
1. 研究一下为什么SiamRPN那么快，它的骨干网络是什么，网络参数量和运算量分别是多少。
2. 研究一下anchor free的tracker，先移过来。
3. RepVGG，把 MobileONE 的训练技巧复现一下。
4. 迅速将anchor free部署到Android，在原有的架构上改进。
   先做第二点，看一下ocean.
结果：
1. 跑通了trackit的测试代码，得到了Ocean的结构
2. 试着用anchor的尺寸作为卷积的尺寸进行特征提取
3. 






框架的要求
1. 支持测试的数据集：OTB、got10k、VOT数据集测试程序的编写，要有FPS。
    支持训练的数据集：VID、COCO、got10k，测试和训练分开。
2. 神经网络参数量测量程序的编写。
3. 各数据集的读取，以及dataloader的编写。
4. 激活函数换成ReLU6。
5. backbone、RPN、在这中间，应该使用注意力机制来搞，要思考如何将这些提取到的特征更高效的运用起来。
6. 硬件移植，先搞edgeboard和K510，来年Jetson orin nano发布之后，如果能买到，使用orin nano进行部署。
7. lighttracking、FEAR-L、FEAR-XS、FEAR-M、Ocean（Offline）、STARK（S-50）、SiamFC++（AlexNet）、SiamFC++（GoogleNet）、
	SiamRPN++（mobileNet-v2）、SiamRPN++（ResNet-50）的实现，并且整合到框架中，而不是多个项目工程同时跑数据、LightTrack、STARK（Lighting）
8. Efficient-net、mobile-net v2、RepVGG的训练方式、MobileOne的组织结构，都要学一下。
9. 要有logging，要有断点续训，不需要分布式，针对不同的算法要生成不同的文件夹来存放数据，不然每次要改就很烦。
10. 测试工具：vot toolkit   pysot toolkit  vot toolkit


要尽量使用别人写好的代码，而不要试图自己去写完所有的代码，最好找已经存在的库来做。


1. 尽量少的分支
2. 尽量少的分组
3. 尽量使用3*3卷积
4. 输入通道和输出通道尽可能一致
5. 尽量少的element操作
6. 目标是尽量少的参数量 + 尽量少的MAC



